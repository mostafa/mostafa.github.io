<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.1">Jekyll</generator><link href="https://mostafa.dev/feed.xml" rel="self" type="application/atom+xml" /><link href="https://mostafa.dev/" rel="alternate" type="text/html" /><updated>2020-05-27T23:37:31+02:00</updated><id>https://mostafa.dev/feed.xml</id><title type="html">Mostafa’s personal blog</title><subtitle>Mostafa Moradian's personal website &amp; blog about software engineering, security and other related topics.</subtitle><entry><title type="html">DevRel Content Strategies</title><link href="https://mostafa.dev/blog/devrel-content-strategies" rel="alternate" type="text/html" title="DevRel Content Strategies" /><published>2020-05-15T00:00:00+02:00</published><updated>2020-05-15T00:00:00+02:00</updated><id>https://mostafa.dev/blog/devrel-content-strategies</id><content type="html" xml:base="https://mostafa.dev/blog/devrel-content-strategies">&lt;p&gt;The very first &lt;a href=&quot;https://devrel.events/developer-relations-online-event/&quot;&gt;developer relations online meetup&lt;/a&gt; of Stockholm was streamed live on Facebook on April 15, 2020. It was also recorded and later published on YouTube for those who couldn’t attend.&lt;/p&gt;

&lt;p&gt;The event was organized and streamed by &lt;a href=&quot;https://twitter.com/iWozik&quot;&gt;Oleg Pridiuksson&lt;/a&gt;, who is a decade-old experienced developer advocate who worked for great companies like King and Unity. He is now a developer relations program consultant and basically founded the &lt;a href=&quot;https://www.eventbrite.com/o/developer-relations-events-26740448969&quot;&gt;Developer Relations Sweden&lt;/a&gt; meetup group.&lt;/p&gt;

&lt;p&gt;There were three speakers: &lt;strong&gt;&lt;em&gt;Hassan Al Kazmi&lt;/em&gt;&lt;/strong&gt;, who is an artist advocate at King, who talked and answered questions about “how much support should a developer advocate provide”. The next speaker was &lt;strong&gt;&lt;em&gt;Janina Łaszkiewicz&lt;/em&gt;&lt;/strong&gt;, an agile coach, community manager, founder of Eventspace.by, who also talked and answered questions about “doing events so developers like them 3000”. Their talks were more of an unconference, where Oleg used to ask questions and the speakers would answer and discuss the answers. You can watch the &lt;a href=&quot;https://www.youtube.com/watch?v=YHj5HiV2fPA&quot;&gt;5 minutes summary&lt;/a&gt; of the online event.&lt;/p&gt;

&lt;p&gt;I went into reverse by presenting with slides about “&lt;a href=&quot;https://www.youtube.com/watch?v=-9MS4U1QH7c&quot;&gt;DevRel content strategies with a focus on SEO optimization for developers&lt;/a&gt;”, instead of the casual unconference style.&lt;/p&gt;

&lt;p&gt;My talk was based on an article, named “&lt;a href=&quot;https://www.animalz.co/blog/diversified-content-portfolio/&quot;&gt;Risk vs. Reward: How to Build a Diversified Content Portfolio&lt;/a&gt;” by Ryan Law. I took this article as the basis of my talk and then added the sauce of experience on my Medium articles about one single article about security, “&lt;a href=&quot;https://medium.com/swlh/secure-code-review-and-penetration-testing-of-node-js-and-javascript-apps-41485b1a9518&quot;&gt;Secure Code Review and Penetration Testing of Node.js and JavaScript Apps&lt;/a&gt;”, and a series of articles I’ve published about &lt;a href=&quot;https://medium.com/swlh/beginners-guide-to-load-testing-with-k6-85ec614d2f0d&quot;&gt;load testing with k6&lt;/a&gt;. I took the stats from Medium and tried to re-frame and present them in a way the conforms to the recommendations laid out in the article.&lt;/p&gt;

&lt;p&gt;Although I have presented the talk on a DevRel event and it is named “DevRel Content Strategies”, it is still beneficial to anyone publishing content over the internet, no matter the area of interest.&lt;/p&gt;

&lt;p&gt;I hope you’ll find it useful and I am happy to hear your feedback.&lt;/p&gt;</content><author><name></name></author><summary type="html">The very first developer relations online meetup of Stockholm was streamed live on Facebook on April 15, 2020. It was also recorded and later published on YouTube for those who couldn’t attend.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://mostafa.dev/img/1*hoKJNJyKPJEDwBw71pL-UQ.png" /><media:content medium="image" url="https://mostafa.dev/img/1*hoKJNJyKPJEDwBw71pL-UQ.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Load Testing Your API with Postman</title><link href="https://mostafa.dev/blog/load-testing-your-api-with-postman" rel="alternate" type="text/html" title="Load Testing Your API with Postman" /><published>2020-04-21T00:00:00+02:00</published><updated>2020-04-21T00:00:00+02:00</updated><id>https://mostafa.dev/blog/load-testing-your-api-with-postman</id><content type="html" xml:base="https://mostafa.dev/blog/load-testing-your-api-with-postman">&lt;p&gt;In this article, I’ll explain how to use a Postman collection I have created to load test our instance of our test API. The process is pretty straightforward, as is shown below. You need to feed your exported Postman collection to our postman-to-k6 converter, and use the generated k6 script to load test your own API.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# convert postman collection to k6 test&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;postman-to-k6 test-api.json &lt;span class=&quot;nt&quot;&gt;-e&lt;/span&gt; env.json &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt; k6-script.js
&lt;span class=&quot;c&quot;&gt;# run load test  &lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;k6 run &lt;span class=&quot;nt&quot;&gt;--vus&lt;/span&gt; 100 &lt;span class=&quot;nt&quot;&gt;--duration&lt;/span&gt; 5m k6-script.js
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h3 id=&quot;our-test-api--its-testing-scenario&quot;&gt;Our Test API &amp;amp; Its Testing Scenario&lt;/h3&gt;

&lt;p&gt;In order to demonstrate the power of k6 in different scenarios, we have created our test API with various example endpoints, which is available at &lt;a href=&quot;https://test-api.k6.io&quot;&gt;test-api.k6.io&lt;/a&gt;. These endpoints are available in the Postman collection:&lt;/p&gt;

&lt;h3 id=&quot;public-apis&quot;&gt;Public APIs&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;List all public crocodiles&lt;/li&gt;
  &lt;li&gt;Get a single public crocodile
    &lt;h3 id=&quot;registration-and-authentication&quot;&gt;Registration and authentication&lt;/h3&gt;
  &lt;/li&gt;
  &lt;li&gt;Register a new user&lt;/li&gt;
  &lt;li&gt;Bearer/JWT token authentication
    &lt;h3 id=&quot;private-apis&quot;&gt;Private APIs&lt;/h3&gt;
  &lt;/li&gt;
  &lt;li&gt;List all your crocodiles&lt;/li&gt;
  &lt;li&gt;Get a single crocodile&lt;/li&gt;
  &lt;li&gt;Create a new crocodile (max 100)&lt;/li&gt;
  &lt;li&gt;Update your crocodile&lt;/li&gt;
  &lt;li&gt;Update selected fields on your crocodile&lt;/li&gt;
  &lt;li&gt;Remove your crocodile
The scenario is to test all the public and private APIs. For the private APIs, a user is created and its token is extracted. The extracted token is used to make other API calls. The order is very important in the private APIs, since you cannot delete a non-existing resource, for example. By the way, crocodile is our mascot.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;our-test-api-postman-collection&quot;&gt;Our Test API Postman Collection&lt;/h3&gt;

&lt;p&gt;To ease testing of our test API and demonstrate the usage of our Postman to k6 converter, I’ve created a Postman collection with almost all of our test API requests. You’ll see how you can access this Postman collection shortly.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/1*1IOClfhM1VmtqaSXUn4nzA.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This collection includes a set of collection variables, environment variables, pre-scripts, tests, authorization with two different mechanisms, and usages of the &lt;a href=&quot;https://learning.postman.com/docs/postman/scripts/postman-sandbox-api-reference/&quot;&gt;Postman Sandbox API&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;load-testing-our-test-api-with-the-postman-collection&quot;&gt;Load Testing Our Test API with The Postman Collection&lt;/h3&gt;

&lt;p&gt;We have created a tool that converts your Postman collection to k6 script, which is called &lt;a href=&quot;https://github.com/loadimpact/postman-to-k6&quot;&gt;postman-to-k6&lt;/a&gt;. You can read more about its features in its &lt;a href=&quot;https://blog.loadimpact.com/new-postman-to-k6-converter-tool-with-support-for-pre-request-and-test-scripts&quot;&gt;release notes&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In order to convert your Postman collection to k6 script, you should take the following steps:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1. Optional: Clone the repository and skip to the step 5&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;I’ve created a repository for this article that contains the exported Postman collection, along with the converted script and related files. You can clone the repository and import the test-api.json and env.json files into the Postman application and possibly play with them if you want.&lt;/p&gt;

&lt;p&gt;This repository contains everything that is needed for load testing our test API, so you can skip to step 4. When using your own collection, you should take all the steps to be able to have a k6 script out of your Postman collection, and to be able to run your load test with it.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;git clone &amp;lt;https://github.com/k6io/example-postman-collection.git&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;2. Install Node.js (if you haven’t already done so)&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;For this, I highly recommend that you use something like &lt;a href=&quot;https://github.com/nvm-sh/nvm&quot;&gt;nvm&lt;/a&gt;, which is a Node.js version manager that you can use to have multiple version of Node.js at the same time on your machine and be able to switch to any of them quickly.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3. Install the postman-to-k6 tool&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;The &lt;a href=&quot;https://github.com/loadimpact/postman-to-k6&quot;&gt;postman-to-k6&lt;/a&gt; tool is developed to help you convert the requests inside your Postman collections to k6 scripts, which are actually JavaScript code.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;npm &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-g&lt;/span&gt; postman-to-k6
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;4. Convert your exported Postman collection to k6 script&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;Assuming your exported collection is named test-api.json, you can run this command to convert it to a k6 script. The env.json includes all your environment variables that are exported from Postman.&lt;/p&gt;

&lt;p&gt;$ postman-to-k6 test-api.json -e env.json -o k6-script.jsIf you need more fine-tuning of your test (like we did above), like adding data or changing environment variables inside your code, just take a look at the Options section of the &lt;a href=&quot;https://github.com/loadimpact/postman-to-k6#options&quot;&gt;postman-to-k6 README&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The script generated by the converter should look like below. As you see, I’ve manually added the &lt;a href=&quot;https://k6.io/docs/using-k6/options#duration&quot;&gt;duration&lt;/a&gt; (of the test run) to be 1 minute and also added the &lt;a href=&quot;https://k6.io/docs/using-k6/options#vus&quot;&gt;virtual users (VU)&lt;/a&gt; count. These two options let the script run for a minute with 100 virtual users. These 100 VUs try to make as many requests as they can to test the server, which you’ll see in the next screenshot.&lt;/p&gt;

&lt;p&gt;The generated script is a little bit different from normal k6 scripts, since it includes various abstractions to support different Postman functionality, but you can mix them with regular &lt;a href=&quot;https://docs.k6.io/docs/http-requests&quot;&gt;http requests&lt;/a&gt; from k6. Also, there is a libs directory beside the script that includes shims and libraries needed for the Postman scripts to work correctly.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;5. Install k6&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;k6 supports various platforms, including Windows, Linux, macOS and docker. In order to &lt;a href=&quot;https://docs.k6.io/docs/installation&quot;&gt;install&lt;/a&gt; it, just grab an &lt;a href=&quot;https://dl.bintray.com/loadimpact/windows/k6-latest-amd64.msi&quot;&gt;Windows installer&lt;/a&gt; or a &lt;a href=&quot;https://hub.docker.com/r/loadimpact/k6&quot;&gt;docker image&lt;/a&gt; and run it on your machine. On Linux distributions, you can use &lt;a href=&quot;https://docs.k6.io/docs/installation#section-linux-deb-and-rpm-packages&quot;&gt;APT or YUM&lt;/a&gt;, and on macOS, you can use &lt;a href=&quot;https://docs.k6.io/docs/installation#section-mac-brew&quot;&gt;Homebrew&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;NOTE:&lt;/em&gt; Regarding installation on Windows, you can also use &lt;a href=&quot;https://chocolatey.org/packages/k6&quot;&gt;choco k6 package&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;6. Run k6 with the generated script&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;Now that you have your collections converted into a k6 script, you can invoke k6 like this:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;k6 run k6-script.js
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The result of running the script is shown in the following console output:&lt;/p&gt;

&lt;h3 id=&quot;remarks-about-using-the-postman-to-k6-converter&quot;&gt;Remarks about using the postman-to-k6 converter&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;1️. Should we base our load tests on the Postman converter and our Postman collections?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;If you’re using the converter as a way of onboarding, no. If you expect to convert your collection continuously and without doing a lot of manual edits afterwards, yes.&lt;/p&gt;

&lt;p&gt;We recommend you to use the converter as an easy way to onboard and then rewrite your scripts to idiomatic k6 code, as we believe it to be more maintainable and less likely to degrade over time. If you convert from postman collections continuously, however, and run the script output as-is, it might make sense to keep it as is.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2. Is everything available out of the box in the converted script?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;No. Since k6 uses Goja to run JavaScript, and it is not compatible with browsers’ and Node.js APIs, hence there are some missing functionality. This can be fixed by &lt;a href=&quot;https://k6.io/docs/using-k6/modules&quot;&gt;importing bundled JavaScript modules&lt;/a&gt;. For a list of compatible libraries, please see &lt;a href=&quot;https://jslib.k6.io/&quot;&gt;jslib.k6.io&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3. What adjustments did you make to the script to make it work?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;First, I removed the pre-script containing pm.sendRequest, because it is not supported by the converter. Then, I replaced the jsonData.hasOwnProperty syntax with the equivalent k6 syntax for &lt;a href=&quot;https://k6.io/docs/javascript-api/k6-http/response-k6-http&quot;&gt;extracting JSON response information&lt;/a&gt;: response.json(“selector”).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/0*TWNwoEeJEr0z9YUb.png&quot; alt=&quot;&quot; /&gt;### Postman API vs. k6 API&lt;/p&gt;

&lt;p&gt;Here’s a quick comparison of the &lt;a href=&quot;https://learning.postman.com/docs/postman/scripts/postman-sandbox-api-reference/&quot;&gt;Postman API&lt;/a&gt; versus the &lt;a href=&quot;https://k6.io/docs/javascript-api&quot;&gt;k6 API&lt;/a&gt;. To be fair, I have included features from Postman GUI application. Since k6 is scriptable from the start, you have the option to write the logic in JavaScript. Postman also supports javascript to do various tasks, but the focus is on exposing features via a richer set of GUI elements.&lt;/p&gt;

&lt;p&gt;As you saw above, there are many features supported by each API, each to some extent. Some features needs external libraries, some are internal. Both APIs are scriptable in JavaScript, and not everything is supported by both, due to the various browser and Node.js APIs used in the libraries.&lt;/p&gt;

&lt;p&gt;Yet, there are some features only available on k6, which is partially due to the fact that the Postman is catered for API testing or API functional testing, but k6 is focused more on API load testing.&lt;/p&gt;

&lt;h4 id=&quot;functional-testing-vs-load-testing&quot;&gt;Functional testing vs. load testing&lt;/h4&gt;

&lt;p&gt;Functional testing concerns with giving input to the system (as a black-box) via an API and examining the results, while load testing is basically doing the same thing as functional testing, but with additional &lt;strong&gt;load&lt;/strong&gt; on the input to the system.&lt;/p&gt;

&lt;p&gt;Functional testing provides input on each endpoint, and the returned results are verified in terms of correctness against a set of specifications. In turn, load testing provides a huge amount of load on each endpoint, and rather tries to aggregate the metadata returned by all the responses.&lt;/p&gt;

&lt;h4 id=&quot;load-testing-metrics-for-measuring-performance&quot;&gt;Load testing metrics for measuring performance&lt;/h4&gt;

&lt;p&gt;Concerning the measurements, the metadata will include the time it took for the request to settle and the response to return, which are measure by various &lt;a href=&quot;https://k6.io/docs/using-k6/metrics&quot;&gt;metrics&lt;/a&gt;. For example you can measure the HTTP request duration of all requests and get their minimum, maximum, average, median, 90th and 95th percentiles.&lt;/p&gt;

&lt;h4 id=&quot;passfail-a-test-with-thresholds&quot;&gt;Pass/fail a test with thresholds&lt;/h4&gt;

&lt;p&gt;You also have the option to pass/fail a test if it does/doesn’t reach certain &lt;a href=&quot;https://k6.io/docs/using-k6/thresholds&quot;&gt;threshold(s)&lt;/a&gt;. For example, you can specify that you want the average response time to be less than 500ms. If the average is below that, the test will fail, much like asserts in software testing.&lt;/p&gt;

&lt;h4 id=&quot;filter-results-with-tags&quot;&gt;Filter results with tags&lt;/h4&gt;

&lt;p&gt;Since you’re dealing with lots of different results from different endpoints, your life would be easier if you could filter the results. &lt;a href=&quot;https://k6.io/docs/using-k6/tags-and-groups#tags&quot;&gt;Tags&lt;/a&gt; are supported by k6 to fulfill this requirement.&lt;/p&gt;

&lt;h4 id=&quot;load-testing-websocket-servers&quot;&gt;Load testing WebSocket servers&lt;/h4&gt;

&lt;p&gt;In terms of protocol implementation, &lt;a href=&quot;https://k6.io/docs/using-k6/protocols/websockets&quot;&gt;WebSocket&lt;/a&gt; is one of the features available only in k6, compared to Postman, and you can load test your WebSocket server with it.&lt;/p&gt;

&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;In this article I’ve tried to give a quick introduction to Postman, the postman-to-k6 converter and our k6 load testing tool. All these tools combined can help you turn your API requests in Postman into k6 script in order to load test your API. Many of the Postman features are supported by the postman-to-k6 tool.&lt;/p&gt;

&lt;p&gt;Our ultimate goal is to streamline the process of onboarding you to our load testing tool, k6. In doing so, we have created a bunch of &lt;a href=&quot;https://k6.io/docs/integrations&quot;&gt;tools&lt;/a&gt; that can help you easily integrate load testing in your infrastructure.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Originally published at &lt;a href=&quot;https://k6.io/blog/load-testing-with-postman-collections&quot;&gt;https://k6.io&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">In this article, I’ll explain how to use a Postman collection I have created to load test our instance of our test API. The process is pretty straightforward, as is shown below. You need to feed your exported Postman collection to our postman-to-k6 converter, and use the generated k6 script to load test your own API. # convert postman collection to k6 test $ postman-to-k6 test-api.json -e env.json -o k6-script.js # run load test $ k6 run --vus 100 --duration 5m k6-script.js Our Test API &amp;amp; Its Testing Scenario</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://mostafa.dev/img/1*Qe-NONu2psPiePB_MX1RjA.png" /><media:content medium="image" url="https://mostafa.dev/img/1*Qe-NONu2psPiePB_MX1RjA.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Load Testing Your API with Swagger/OpenAPI and k6</title><link href="https://mostafa.dev/blog/load-testing-your-api-with-swagger-openapi-and-k6" rel="alternate" type="text/html" title="Load Testing Your API with Swagger/OpenAPI and k6" /><published>2020-03-23T00:00:00+01:00</published><updated>2020-03-23T00:00:00+01:00</updated><id>https://mostafa.dev/blog/load-testing-your-api-with-swagger-openapi-and-k6</id><content type="html" xml:base="https://mostafa.dev/blog/load-testing-your-api-with-swagger-openapi-and-k6">&lt;h4 id=&quot;overview&quot;&gt;Overview&lt;/h4&gt;

&lt;p&gt;Throughout the years, there has been many attempts to devise &lt;a href=&quot;https://en.wikipedia.org/wiki/Overview_of_RESTful_API_Description_Languages&quot;&gt;a universal format for defining Web API specifications&lt;/a&gt;. The objective was (and still is) to help stakeholders of the system to work with those APIs, without having access to the source code. Each new “universal” format came with the promise of being ubiquitous and all-encompassing, but eventually faded away due to various reasons, like &lt;a href=&quot;https://en.wikipedia.org/wiki/Open_Data_Protocol&quot;&gt;OData&lt;/a&gt; and &lt;a href=&quot;https://en.wikipedia.org/wiki/Web_Services_Description_Language&quot;&gt;WSDL&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;One of the major players in this field is &lt;a href=&quot;https://en.wikipedia.org/wiki/Swagger_%28software%29&quot;&gt;Swagger&lt;/a&gt;, developed by Tony Tam in 2011, which later was hired by the SmartBear Software, effectively &lt;a href=&quot;https://smartbear.com/news/news-releases/swagger-creator-tony-tam-joins-smartbear-software/&quot;&gt;acquiring the rights to the software&lt;/a&gt;. In 2015, the same company created a new organization under the sponsorship of the Linux Foundation and called it the OpenAPI Initiative. The new initiative has renamed the Swagger specification to &lt;a href=&quot;https://en.wikipedia.org/wiki/OpenAPI_Specification&quot;&gt;OpenAPI Specification (OAS)&lt;/a&gt; in 2016. This specification is generally used for developing, interacting and documenting APIs.&lt;/p&gt;

&lt;p&gt;There are many uses-cases to OpenAPI. The first is to use it as a documentation for your APIs. Usually it is generated from the request handlers along with the schema for your database models and fields. The second is to use it as a means to generate server-side code, that is the actual API. This is particularly useful for those who want to go spec-first, rather than code-first. The third is to use as a means to generate client-side code. With this method, you’ll have stubs generated for all your requests, which can be used to make use of or even test your APIs.&lt;/p&gt;

&lt;p&gt;Overall, the OpenAPI specification and the &lt;a href=&quot;https://github.com/OpenAPITools/openapi-generator&quot;&gt;openapi-generator project&lt;/a&gt; can help you generate a lot of integrations out of the box from your API specification. Imagine you could have a specification document that can help you generate your server-side code to serve API endpoints, your client-side code for testing and the documentation of your API for developers and testers.&lt;/p&gt;

&lt;h4 id=&quot;swaggeropenapi-load-testing&quot;&gt;Swagger/OpenAPI load testing&lt;/h4&gt;

&lt;p&gt;Formerly, the idea of Swagger/OpenAPI load testing was taken less seriously by the developer community. It was due to the fact that only QA people used to work on performance testing. k6 takes load testing to a whole another level by letting &lt;strong&gt;developers&lt;/strong&gt; write their own load test scripts in JavaScript. With the introduction of new tools, like k6, and then the widespread use of Swagger/OpenAPI for API design and documentation, we felt the need that tools for transforming Swagger/OpenAPI specifications to scripts to be used for performance testing should exist.&lt;/p&gt;

&lt;p&gt;We thought it would be a good idea to have a tool to generate a load test script out of an OpenAPI specification document. This new generator will then help you easily integrate load testing in your infrastructure. Therefore, we have added a &lt;a href=&quot;https://github.com/OpenAPITools/openapi-generator/pull/5300&quot;&gt;new k6 generator&lt;/a&gt; to the openapi-generator project.&lt;/p&gt;

&lt;p&gt;By using this tool, as a Swagger/OpenAPI test generator, you can now generate your k6 load test scripts using the same specification documents you used for your APIs. We tried our best to convert &lt;em&gt;almost&lt;/em&gt; all the specification to k6 script, but the generated script should still be modified to make it runnable and suitable for your use case.&lt;/p&gt;

&lt;p&gt;Once you have a working script, you can easily use it in your Continuous Integration (CI) platform to automate load testing. You can also use our SaaS offering, &lt;a href=&quot;https://k6.io/cloud&quot;&gt;k6 Cloud&lt;/a&gt;, that gives you the ability to run your load tests in a distributed environment from various regions, plus giving you detailed insights on the results of your test(s).&lt;/p&gt;

&lt;h4 id=&quot;api-load-testing-with-swaggeropenapi-specification&quot;&gt;API load testing with Swagger/OpenAPI specification&lt;/h4&gt;

&lt;p&gt;We have written a guide for &lt;a href=&quot;https://k6.io/docs/testing-guides/api-load-testing&quot;&gt;API load testing&lt;/a&gt; and since OpenAPI is concerned with APIs, we advise you to take a look at the guide. It will help you understand why you should load test your APIs. The guide gives you an overview of different approaches to API load testing. It includes various ways to create load test scripts, from writing one yourself, to using your existing Postman collections or HAR files and converting them to load test scripts. It also provides you with considerations you need to know while load testing your APIs.&lt;/p&gt;

&lt;h4 id=&quot;generating-load-test-script-from-swaggeropenapi-specification&quot;&gt;Generating load test script from Swagger/OpenAPI specification&lt;/h4&gt;

&lt;p&gt;There are various ways to install the &lt;a href=&quot;https://github.com/OpenAPITools/openapi-generator#1---installation&quot;&gt;openapi-generator&lt;/a&gt;. It is distributed in source code, so that you can build it yourself. You have lots of options to use binaries for your operating system. We recommend using the &lt;a href=&quot;https://hub.docker.com/r/openapitools/openapi-generator-cli/&quot;&gt;Docker image&lt;/a&gt;, which is going to be explained in this article.&lt;/p&gt;

&lt;p&gt;I assume you have docker installed, otherwise have a look at the &lt;a href=&quot;https://docs.docker.com/install/&quot;&gt;installation&lt;/a&gt; instructions for your operating system. The following commands pulls the Docker image for you. You can also omit this command in favor of the next one, because it pulls the latest image for you, if you don’t have it on your machine.&lt;/p&gt;

&lt;p&gt;$ docker pull openapitools/openapi-generator-cliThe next step is to run the command inside a container to convert the OpenAPI specification file for you. Assuming you are running Docker on Linux-based operating systems, the following command mounts your present working directory (e.g. /home/user/Desktop) to /local on the container. Also note that after conversion, the container is removed. The container runs the command inside it with the generate option, along with its parameters.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;docker run &lt;span class=&quot;nt&quot;&gt;--rm&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-v&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;PWD&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;:/local openapitools/openapi-generator-cli generate-i http://httpbin.test.loadimpact.com/spec.json &lt;span class=&quot;nt&quot;&gt;-g&lt;/span&gt; k6 &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt; /local/k6-test/ &lt;span class=&quot;nt&quot;&gt;--skip-validate-spec&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;With the above command, we’ve converted the API specification document of the &lt;a href=&quot;https://httpbin.org/&quot;&gt;httpbin.org&lt;/a&gt; instance, that is hosted on our servers. The parameters are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The -i parameter is used to feed the specification document to the generator. You can use a file for that purpose. This way you should make sure that it resides in the same directory on your host (/home/user/Desktop/myspec.json), and you address it from the container side: /local/myspec.json. You also have the option to specify a URL that points to a file. Note that the file can be in either JSON or YAML format.&lt;/li&gt;
  &lt;li&gt;The -g parameter specifies the generator to use, that is k6.&lt;/li&gt;
  &lt;li&gt;The -o parameter specifies the directory to store the generated files. After conversion, the files can be accessed from /home/user/Desktop/k6-test/ on your host.&lt;/li&gt;
  &lt;li&gt;In case you get a lot of errors from validation, just skip them with –skip-validate-spec. These errors are often related to differences between Swagger and OpenAPI specification.
    &lt;h4 id=&quot;load-testing-using-the-generated-script&quot;&gt;Load testing using the generated script&lt;/h4&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The script should definitely be cleaned up after conversion. The original script is too long to fit into this article, thus the following example is an snippet of the generated script. Extra comments and unneeded code has been removed for demonstration purposes and the n variable is initialized.&lt;/p&gt;

&lt;p&gt;Running the above script has produced the following output:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/0*LB9Sr2Mt7bMEdiuy.png&quot; alt=&quot;&quot; /&gt;#### Considerations for the generated script&lt;/p&gt;

&lt;p&gt;Take these into consideration while converting your OpenAPI specification documents to k6 scripts:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The order of the requests follow the order in the specification document and may not always be correct. Replace them to match your request/response flow. For example, you first create a resource with POST, then you read it with GET.&lt;/li&gt;
  &lt;li&gt;All requests belonging to the same path are grouped together with the k6 &lt;a href=&quot;https://k6.io/docs/using-k6/tags-and-groups&quot;&gt;group&lt;/a&gt; feature.&lt;/li&gt;
  &lt;li&gt;A global sleep duration is defined with the SLEEP_DURATION variable and for each request, the value is applied using the k6 &lt;a href=&quot;https://k6.io/docs/javascript-api/k6/sleep-t&quot;&gt;sleep&lt;/a&gt; function. Change them to match the delay you need between the requests.&lt;/li&gt;
  &lt;li&gt;Make sure the BASE_URL is correct.&lt;/li&gt;
  &lt;li&gt;Initialize all variables that their value starts with “TODO_EDIT_THE_…”.&lt;/li&gt;
  &lt;li&gt;Body parameters are in the form of { variable: “datatype” }. Change the datatype to the desired value. Nested body parameters follow the same pattern.&lt;/li&gt;
  &lt;li&gt;For file upload endpoints that use &lt;a href=&quot;https://k6.io/docs/using-k6/multipart-requests-file-uploads&quot;&gt;multipart requests&lt;/a&gt;, replace the file name with your own.&lt;/li&gt;
  &lt;li&gt;You &lt;em&gt;may&lt;/em&gt; encounter undefined variables being used. Just add them manually. It may be due to differences between OpenAPI and Swagger specifications.&lt;/li&gt;
  &lt;li&gt;We only use &lt;a href=&quot;https://k6.io/docs/using-k6/checks&quot;&gt;checks&lt;/a&gt; for the default and 200 OK responses for now. It is up to you to check for the rest.&lt;/li&gt;
  &lt;li&gt;If you found any issues, please file it on &lt;a href=&quot;https://github.com/loadimpact/openapi-generator/issues&quot;&gt;issues&lt;/a&gt;.
    &lt;h4 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h4&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The k6 generator for OpenAPI was written to onboard users to k6. The tool is going to help users quickly generate a load test script out of their existing Swagger/OpenAPI specification documents. This auto-generation of the load test script will help streamline the API testing process, keeping on par with the latest changes to their APIs and specifications.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Originally published at &lt;a href=&quot;https://k6.io/blog/load-testing-your-api-with-swagger-openapi-and-k6&quot;&gt;https://k6.io&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">Overview</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://mostafa.dev/img/0*2_0U-DPmTzBEJspg.png" /><media:content medium="image" url="https://mostafa.dev/img/0*2_0U-DPmTzBEJspg.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">microVM: Another Level of Abstraction for Serverless Computing</title><link href="https://mostafa.dev/blog/microvm-another-level-of-abstraction-for-serverless-computing" rel="alternate" type="text/html" title="microVM: Another Level of Abstraction for Serverless Computing" /><published>2019-12-16T00:00:00+01:00</published><updated>2019-12-16T00:00:00+01:00</updated><id>https://mostafa.dev/blog/microvm--another-level-of-abstraction-for-serverless-computing</id><content type="html" xml:base="https://mostafa.dev/blog/microvm-another-level-of-abstraction-for-serverless-computing">&lt;p&gt;For years, cloud computing was a way to convince users and business to spend their money hosting their services on servers collocated on cloud data-centers. Things are changed and merely providing basic storage and processing power is a thing of the past. Cloud services are so complicated today that each one of them needs proper training to just be able to use them. Distributed data-stores, load-balancers, storages, serverless and container automation and orchestration services are just a few example of the vast number of cloud computing services.&lt;/p&gt;

&lt;p&gt;One can now have a software running on cloud services (Software-as-a-Service) with &lt;a href=&quot;https://en.wikipedia.org/wiki/High_availability#Percentage_calculation&quot;&gt;five-nine SLA&lt;/a&gt; hosted on multiple cloud providers, effectively providing high-availability across the globe, all controlled from a central location, automated and orchestrated with the latest cutting-edge technologies on the market. And the number of these technologies are ever-growing.&lt;/p&gt;

&lt;p&gt;Most of the cloud providers today use open-source model to distribute their technologies and software. Examples of which are &lt;a href=&quot;https://github.com/kubernetes/kubernetes&quot;&gt;kubernetes&lt;/a&gt;, &lt;a href=&quot;https://github.com/docker/docker-ce&quot;&gt;docker&lt;/a&gt; and &lt;a href=&quot;https://github.com/firecracker-microvm/firecracker&quot;&gt;firecracker&lt;/a&gt;. Containerization and light-weight virtual machines are just two of the various ways to deploy applications on cloud. Each has its own pros and cons. But in this article I am going to present firecrack, a light-weight virtual machine, or microVM, management tool created by Amazon to run their serverless platform. In contrast to containerization, specifically docker, which uses a single shared Linux kernel with cgroups, namespaces, etc., microVMs use a separate Linux kernel virtualized on top of kernel-based virtual machine (KVM). The advantages of microVM are less memory overhead (5 MB), very minimal optimized kernel and security. The most interesting part is that it is written in &lt;a href=&quot;http://rust-lang.org/&quot;&gt;Rust&lt;/a&gt;, has an awesome &lt;a href=&quot;http://golang.org/&quot;&gt;Go&lt;/a&gt; SDK and many tools are already developed for it:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/firecracker-microvm/firecracker&quot; title=&quot;https://github.com/firecracker-microvm/firecracker&quot;&gt;&lt;strong&gt;firecracker-microvm/firecracker&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Our mission is to enable secure, multi-tenant, minimal-overhead execution of container and function workloads. Read…&lt;/em&gt;github.com&lt;/a&gt;&lt;a href=&quot;https://github.com/firecracker-microvm/firecracker&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/firecracker-microvm/firecracker-containerd&quot; title=&quot;https://github.com/firecracker-microvm/firecracker-containerd&quot;&gt;&lt;strong&gt;firecracker-microvm/firecracker-containerd&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Automation Status Tests Lint This repository enables the use of a container runtime, containerd, to manage Firecracker…&lt;/em&gt;github.com&lt;/a&gt;&lt;a href=&quot;https://github.com/firecracker-microvm/firecracker-containerd&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/firecracker-microvm/firecracker-go-sdk&quot; title=&quot;https://github.com/firecracker-microvm/firecracker-go-sdk&quot;&gt;&lt;strong&gt;firecracker-microvm/firecracker-go-sdk&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;This package is a Go library to interact with the Firecracker API. It is designed as an abstraction of the…&lt;/em&gt;github.com&lt;/a&gt;&lt;a href=&quot;https://github.com/firecracker-microvm/firecracker-go-sdk&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/firecracker-microvm/firectl&quot; title=&quot;https://github.com/firecracker-microvm/firectl&quot;&gt;&lt;strong&gt;firecracker-microvm/firectl&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Firectl is a basic command-line tool that lets you run arbitrary Firecracker MicroVMs via the command line. This lets…&lt;/em&gt;github.com&lt;/a&gt;&lt;a href=&quot;https://github.com/firecracker-microvm/firectl&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/weaveworks/ignite&quot; title=&quot;https://github.com/weaveworks/ignite&quot;&gt;&lt;strong&gt;weaveworks/ignite&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Weave Ignite is an open source Virtual Machine (VM) manager with a container UX and built-in GitOps management…&lt;/em&gt;github.com&lt;/a&gt;&lt;a href=&quot;https://github.com/weaveworks/ignite&quot;&gt;&lt;/a&gt;There is a demo project demonstrating the abilities and features of microVM by showing how quickly it can run 4k microVMs in less than a minute:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/firecracker-microvm/firecracker-demo&quot; title=&quot;https://github.com/firecracker-microvm/firecracker-demo&quot;&gt;&lt;strong&gt;firecracker-microvm/firecracker-demo&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;This demo showcases Firecracker’s agility and high-density capabilities. It’s been run on an EC2 I3.metal host (the…&lt;/em&gt;github.com&lt;/a&gt;&lt;a href=&quot;https://github.com/firecracker-microvm/firecracker-demo&quot;&gt;&lt;/a&gt;Months ago, I’ve started experimenting with it and wrote a bunch of bash scripts and a simple README to be able to show how to download project binaries or build the project(s) from source and start using microVMs very quickly:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/mostafa/firefighter&quot; title=&quot;https://github.com/mostafa/firefighter&quot;&gt;&lt;strong&gt;mostafa/firefighter&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Firefighter is, for now, as set of scripts to download or build from source the firecracker and the firectl, download…&lt;/em&gt;github.com&lt;/a&gt;&lt;a href=&quot;https://github.com/mostafa/firefighter&quot;&gt;&lt;/a&gt;In order to use it, just clone the project somewhere on your disk and either run get_latest.sh or build_latest.sh. To get the latest binaries along with pre-built Debian and Alpine kernel and rootfs, you just need to have &lt;a href=&quot;https://curl.haxx.se/&quot;&gt;curl&lt;/a&gt; installed. But in order to build it from source code, you should have Rust compiler installed. The easiest way to install Rust compiler and toolchain, just download and install &lt;a href=&quot;https://rustup.rs/&quot;&gt;rustup&lt;/a&gt; installer to be able to easily install other things. A simple tutorial is present on Rust official website that provides instructions on how to do this. For building the latest version, I assume you have &lt;a href=&quot;http://debian.org/&quot;&gt;Debian GNU/Linux&lt;/a&gt; installed, because of APT.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.rust-lang.org/tools/install&quot; title=&quot;https://www.rust-lang.org/tools/install&quot;&gt;&lt;strong&gt;Install Rust&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Using rustup (Recommended) It looks like you’re running macOS, Linux, or another Unix-like OS. To download Rustup and…&lt;/em&gt;www.rust-lang.org&lt;/a&gt;&lt;a href=&quot;https://www.rust-lang.org/tools/install&quot;&gt;&lt;/a&gt;Although building from source gives you full control and customizability, but for mere experimentation, just download the binaries and related files and you’re good to go!&lt;/p&gt;

&lt;p&gt;$ &lt;strong&gt;git clone **&lt;a href=&quot;https://github.com/mostafa/firefighter&quot;&gt;**https://github.com/mostafa/firefighter**&lt;/a&gt;&lt;br /&gt;
$ **cd firefighter&lt;/strong&gt;&lt;br /&gt;
$ &lt;strong&gt;./get_latest.sh&lt;/strong&gt;This script downloads the latest firecracker, firectl and jailer binaries with a progress bar, along with Alpine and Debian kernel and rootfs in images directory.&lt;/p&gt;

&lt;p&gt;Running the following command with no option or with help would print usage instructions:&lt;/p&gt;

&lt;p&gt;$ &lt;strong&gt;./run_microvm.sh&lt;/strong&gt;&lt;br /&gt;
Usage:&lt;br /&gt;
run_microvm.sh start &lt;distro-name&gt; | &lt;vmlinuz.bin&gt; &lt;rootfs.ext4&gt;  
run\_microvm.sh stop  
run\_microvm.sh config  
run\_microvm.sh status  
run\_microvm.sh helpAvailable distros:&lt;/rootfs.ext4&gt;&lt;/vmlinuz.bin&gt;&lt;/distro-name&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;debian&lt;/li&gt;
  &lt;li&gt;alpineTo run an Alpine microVM, just run the following command, it needs root/sudo privilege:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;$ **./run_microvm.sh start alpine&lt;br /&gt;
**Giving read/write access to KVM to user&lt;br /&gt;
[sudo] password for user:&lt;br /&gt;
Booting kernel: images/alpine-vmlinuz.bin&lt;br /&gt;
Image: images/alpine.ext4&lt;br /&gt;
…&lt;br /&gt;
Enable routing from/to MicroVM&lt;br /&gt;
Run MicroVM&lt;br /&gt;
…&lt;br /&gt;
Welcome to Alpine Linux 3.8&lt;br /&gt;
Kernel 4.14.55-84.37.amzn2.x86_64 on an x86_64 (ttyS0)localhost login:Using root as username and password, you can login to the microVM. Run the following commands inside the microVM to enable internet access:&lt;/p&gt;

&lt;p&gt;$ &lt;strong&gt;ip addr add 172.16.0.2/24 dev eth0&lt;/strong&gt;&lt;br /&gt;
$ &lt;strong&gt;ip route add default via 172.16.0.1 dev eth0&lt;/strong&gt;&lt;br /&gt;
$ &lt;strong&gt;echo “nameserver 8.8.8.8” &amp;gt; /etc/resolv.conf&lt;/strong&gt;&lt;br /&gt;
$ **ping -c 3 google.com&lt;br /&gt;
**PING google.com (172.217.20.46): 56 data bytes&lt;br /&gt;
64 bytes from 172.217.20.46: seq=0 ttl=54 time=4.270 ms&lt;br /&gt;
64 bytes from 172.217.20.46: seq=1 ttl=54 time=5.979 ms&lt;br /&gt;
64 bytes from 172.217.20.46: seq=2 ttl=54 time=6.455 ms— google.com ping statistics —&lt;br /&gt;
3 packets transmitted, 3 packets received, 0% packet loss&lt;br /&gt;
round-trip min/avg/max = 4.270/5.568/6.455 msNow you can stop the microVM with the following command on another terminal:&lt;/p&gt;

&lt;p&gt;$ &lt;strong&gt;./run_microvm.sh stop&lt;/strong&gt;That was it for now. You should figure out how you can leverage this to your advantage.&lt;/p&gt;

&lt;p&gt;It’s a simple open-source project and any feedback and contribution is welcome.&lt;/p&gt;

&lt;p&gt;Cover image credits: &lt;a href=&quot;https://firecracker-microvm.github.io/&quot;&gt;https://firecracker-microvm.github.io/&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">For years, cloud computing was a way to convince users and business to spend their money hosting their services on servers collocated on cloud data-centers. Things are changed and merely providing basic storage and processing power is a thing of the past. Cloud services are so complicated today that each one of them needs proper training to just be able to use them. Distributed data-stores, load-balancers, storages, serverless and container automation and orchestration services are just a few example of the vast number of cloud computing services.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://mostafa.dev/img/1*lNlcljTATMVw8oSloQT8tw.png" /><media:content medium="image" url="https://mostafa.dev/img/1*lNlcljTATMVw8oSloQT8tw.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">API &amp;amp; Backend Security</title><link href="https://mostafa.dev/blog/api-backend-security" rel="alternate" type="text/html" title="API &amp; Backend Security" /><published>2019-12-09T00:00:00+01:00</published><updated>2019-12-09T00:00:00+01:00</updated><id>https://mostafa.dev/blog/api---backend-security</id><content type="html" xml:base="https://mostafa.dev/blog/api-backend-security">&lt;p&gt;In my &lt;a href=&quot;https://medium.com/swlh/secure-code-review-and-penetration-testing-of-node-js-and-javascript-apps-41485b1a9518&quot;&gt;previous article&lt;/a&gt; about secure code review and penetration testing of Node.js and JavaScript apps, I tried to give the reader an introduction to the old, but gold, &lt;a href=&quot;https://www.owasp.org/index.php/Category:OWASP_Code_Review_Project&quot;&gt;OWASP Code Review Project&lt;/a&gt; and the &lt;a href=&quot;https://www.owasp.org/index.php/Category:OWASP_Top_Ten_Project&quot;&gt;OWASP Top 10 Project&lt;/a&gt; and to mention the tools of the trade using the simplest approach possible.&lt;/p&gt;

&lt;p&gt;Recently the new &lt;a href=&quot;https://www.owasp.org/index.php/OWASP_API_Security_Project&quot;&gt;OWASP API Security Top 10 2019&lt;/a&gt; is released, as a release candidate, which is a breath of fresh air into the field of security and penetration testing. It is a tribute to its old pal, &lt;a href=&quot;https://www.owasp.org/index.php/Category:OWASP_Backend_Security_Project&quot;&gt;OWASP Backend Security Project&lt;/a&gt;, which was released in 2008, or at least, I see it so, as the naming suggests. But deep down, they are two different guides and two different approaches to security. This new one deals with the Top 10 approach using scenarios, while the old one tries to present a multi-phase approach, with phases being development, hardening and testing.&lt;/p&gt;

&lt;p&gt;In this article I will try to present the new one using all the current tools and techniques available to &lt;em&gt;defend&lt;/em&gt; against threats to your APIs. I will focus on Python, since it is my area of expertise, and would present packages and tools either directly or generally related to it.&lt;/p&gt;

&lt;p&gt;It is really interesting to see how the Top 10 list of software vulnerabilities of an API is different from the original Top 10 list, priority-wise. This sheds a light on the importance of different measures to take.&lt;/p&gt;

&lt;p&gt;The following is the current Top 10 list of vulnerabilities presented in the &lt;a href=&quot;https://github.com/OWASP/API-Security/raw/master/2019/en/dist/owasp-api-security-top-10.pdf&quot;&gt;document&lt;/a&gt;, which I will go through one by one afterwards:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;API1:2019-Broken Object Level Authorization&lt;br /&gt;
API2:2019-Broken Authentication&lt;br /&gt;
API3:2019-Excessive Data Exposure&lt;br /&gt;
API4:2019-Lack of Resources &amp;amp; Rate Limiting&lt;br /&gt;
API5:2019-Broken Function Level Authorization&lt;br /&gt;
API6:2019-Mass Assignment&lt;br /&gt;
API7:2019-Security Misconfiguration&lt;br /&gt;
API8:2019-Injection&lt;br /&gt;
API9:2019-Improper Assets Management&lt;br /&gt;
API10:2019-Insufficient Logging &amp;amp; Monitoring#### API1:2019-Broken Object Level Authorization&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;As the title implies, it is all about giving unwanted parties or attackers extra unnecessary access to information. The &lt;strong&gt;AAA&lt;/strong&gt; &lt;em&gt;(Authentication, Authorization and Accounting)&lt;/em&gt; of network protocols also apply to high-level applications sitting on top of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Application_layer&quot;&gt;Application Layer&lt;/a&gt; (L7) in the TCP/IP network protocol stack, in which, in this case, the &lt;em&gt;Access&lt;/em&gt; would be interchangeably used instead of &lt;em&gt;Accounting&lt;/em&gt;. Although the vulnerability only mentions authorization, I think that other things, like authentication that precedes and access that succeeds it, should also be explored, which I’ll do below.&lt;/p&gt;

&lt;h4 id=&quot;-authentication&quot;&gt;✅ Authentication&lt;/h4&gt;

&lt;p&gt;Authentication is a mechanism by which one’s identity is verified. This means that they have been either identified or unidentified, in advance. This ensures that no one can or will take anyone else’s identity. In applications, identity management is easily described by user management, in which, each user/actor of the system is considered an identity known to the system, which therefore can be verified through a mechanism or a protocol.&lt;/p&gt;

&lt;p&gt;Usually authentication happens via a mechanism or protocol, either application-based or protocol-based, working in different networking stack layers. An example of application-based authentication is the &lt;a href=&quot;https://docs.djangoproject.com/en/2.2/topics/auth/&quot;&gt;user authentication module in Django&lt;/a&gt;, which usually uses a &lt;a href=&quot;https://docs.djangoproject.com/en/2.2/ref/contrib/auth/#django.contrib.auth.backends.ModelBackend&quot;&gt;ModelBackend&lt;/a&gt;* *to filter through a list of users (by username or email) and their matching password existing in a database or a data store. Authentication protocols are either application-layer based ones, like &lt;a href=&quot;https://en.wikipedia.org/wiki/Digest_access_authentication&quot;&gt;digest access authentication&lt;/a&gt;, or they operate on lower layers in the stack, e.g. &lt;a href=&quot;https://en.wikipedia.org/wiki/IEEE_802.1X&quot;&gt;IEEE 802.1X&lt;/a&gt;, though all of which are considered and categorized under &lt;a href=&quot;https://en.wikipedia.org/wiki/Simple_Authentication_and_Security_Layer&quot;&gt;SASL framework&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;These are the things to consider while performing any kind of authentication and authorization and granting access:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;NEVER EVER TRUST USER INPUT! **&lt;/strong&gt;’ or ‘1’=’1**
&lt;a href=&quot;https://github.com/marshmallow-code/marshmallow&quot; title=&quot;https://github.com/marshmallow-code/marshmallow&quot;&gt;&lt;strong&gt;marshmallow-code/marshmallow&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;marshmallow is an ORM/ODM/framework-agnostic library for converting complex datatypes, such as objects, to and from…&lt;/em&gt;github.com&lt;/a&gt;&lt;a href=&quot;https://github.com/marshmallow-code/marshmallow&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/marshmallow-code/webargs&quot; title=&quot;https://github.com/marshmallow-code/webargs&quot;&gt;&lt;strong&gt;marshmallow-code/webargs&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Homepage: https://webargs.readthedocs.io/ webargs is a Python library for parsing and validating HTTP request objects…&lt;/em&gt;github.com&lt;/a&gt;&lt;a href=&quot;https://github.com/marshmallow-code/webargs&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/samuelcolvin/pydantic/&quot; title=&quot;https://github.com/samuelcolvin/pydantic/&quot;&gt;&lt;strong&gt;samuelcolvin/pydantic&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Data validation and settings management using Python type hinting. Fast and extensible, pydantic plays nicely with your…&lt;/em&gt;github.com&lt;/a&gt;&lt;a href=&quot;https://github.com/samuelcolvin/pydantic/&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/pyeve/cerberus&quot; title=&quot;https://github.com/pyeve/cerberus&quot;&gt;&lt;strong&gt;pyeve/cerberus&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Cerberus is a lightweight and extensible data validation library for Python. Cerberus provides type checking and other…&lt;/em&gt;github.com&lt;/a&gt;&lt;a href=&quot;https://github.com/pyeve/cerberus&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://docs.djangoproject.com/en/2.2/ref/models/instances/#validating-objects&quot; title=&quot;https://docs.djangoproject.com/en/2.2/ref/models/instances/#validating-objects&quot;&gt;&lt;strong&gt;Model instance reference | Django documentation | Django&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;This document describes the details of the API. It builds on the material presented in the and database query guides…&lt;/em&gt;docs.djangoproject.com&lt;/a&gt;&lt;a href=&quot;https://docs.djangoproject.com/en/2.2/ref/models/instances/#validating-objects&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/Pylons/colander&quot; title=&quot;https://github.com/Pylons/colander&quot;&gt;&lt;strong&gt;Pylons/colander&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;An extensible package which can be used to: deserialize and validate a data structure composed of strings, mappings…&lt;/em&gt;github.com&lt;/a&gt;&lt;a href=&quot;https://github.com/Pylons/colander&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/keleshev/schema&quot; title=&quot;https://github.com/keleshev/schema&quot;&gt;&lt;strong&gt;keleshev/schema&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;schema is a library for validating Python data structures, such as those obtained from config-files, forms, external…&lt;/em&gt;github.com&lt;/a&gt;&lt;a href=&quot;https://github.com/keleshev/schema&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/schematics/schematics&quot; title=&quot;https://github.com/schematics/schematics&quot;&gt;&lt;strong&gt;schematics/schematics&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Python Data Structures for Humans™. Project documentation: https://schematics.readthedocs.io/en/latest/ Schematics is a…&lt;/em&gt;github.com&lt;/a&gt;&lt;a href=&quot;https://github.com/schematics/schematics&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/podio/valideer&quot; title=&quot;https://github.com/podio/valideer&quot;&gt;&lt;strong&gt;podio/valideer&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Lightweight data validation and adaptation Python library. - podio/valideer&lt;/em&gt;github.com&lt;/a&gt;&lt;a href=&quot;https://github.com/podio/valideer&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/alecthomas/voluptuous&quot; title=&quot;https://github.com/alecthomas/voluptuous&quot;&gt;&lt;strong&gt;alecthomas/voluptuous&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Voluptuous, despite the name, is a Python data validation library. It is primarily intended for validating data coming…&lt;/em&gt;github.com&lt;/a&gt;&lt;a href=&quot;https://github.com/alecthomas/voluptuous&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/Julian/jsonschema&quot; title=&quot;https://github.com/Julian/jsonschema&quot;&gt;&lt;strong&gt;Julian/jsonschema&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;jsonschema is an implementation of JSON Schema for Python (supporting 2.7+ including Python 3). It can also be used…&lt;/em&gt;github.com&lt;/a&gt;&lt;a href=&quot;https://github.com/Julian/jsonschema&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/wesbos/burner-email-providers&quot; title=&quot;https://github.com/wesbos/burner-email-providers&quot;&gt;&lt;strong&gt;wesbos/burner-email-providers&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Throw away email addresses (burner emails) are great for single use signups where you would like the content but rather…&lt;/em&gt;github.com&lt;/a&gt;&lt;a href=&quot;https://github.com/wesbos/burner-email-providers&quot;&gt;&lt;/a&gt;* Authenticate properly, either via SSO, SAML, social authentication or whatever method you choose to authenticate against!
&lt;a href=&quot;https://github.com/python-social-auth/social-core&quot; title=&quot;https://github.com/python-social-auth/social-core&quot;&gt;&lt;strong&gt;python-social-auth/social-core&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Python Social Auth is an easy to setup social authentication/registration mechanism with support for several frameworks…&lt;/em&gt;github.com&lt;/a&gt;&lt;a href=&quot;https://github.com/python-social-auth/social-core&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/davesque/django-rest-framework-simplejwt&quot; title=&quot;https://github.com/davesque/django-rest-framework-simplejwt&quot;&gt;&lt;strong&gt;davesque/django-rest-framework-simplejwt&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;A JSON Web Token authentication plugin for the Django REST Framework. Simple JWT provides a JSON Web Token…&lt;/em&gt;github.com&lt;/a&gt;&lt;a href=&quot;https://github.com/davesque/django-rest-framework-simplejwt&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/pennersr/django-allauth&quot; title=&quot;https://github.com/pennersr/django-allauth&quot;&gt;&lt;strong&gt;pennersr/django-allauth&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Integrated set of Django applications addressing authentication, registration, account management as well as 3rd party…&lt;/em&gt;github.com&lt;/a&gt;&lt;a href=&quot;https://github.com/pennersr/django-allauth&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/IdentityPython/pysaml2&quot; title=&quot;https://github.com/IdentityPython/pysaml2&quot;&gt;&lt;strong&gt;IdentityPython/pysaml2&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;PySAML2 is a pure python implementation of SAML Version 2 Standard. It contains all necessary pieces for building a…&lt;/em&gt;github.com&lt;/a&gt;&lt;a href=&quot;https://github.com/IdentityPython/pysaml2&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/onelogin/python-saml&quot; title=&quot;https://github.com/onelogin/python-saml&quot;&gt;&lt;strong&gt;onelogin/python-saml&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Add SAML support to your Python software using this library. Forget those complicated libraries and use the open source…&lt;/em&gt;github.com&lt;/a&gt;&lt;a href=&quot;https://github.com/onelogin/python-saml&quot;&gt;&lt;/a&gt;* Always use a rate limiting mechanism to disallow users from using a single pair of username and password to authenticate multiple time in a row. This helps prevent brute-force attacks and &lt;a href=&quot;https://www.owasp.org/index.php/Credential_stuffing&quot;&gt;credential stuffing&lt;/a&gt;.
&lt;a href=&quot;https://github.com/tomasbasham/ratelimit&quot; title=&quot;https://github.com/tomasbasham/ratelimit&quot;&gt;&lt;strong&gt;tomasbasham/ratelimit&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;APIs are a very common way to interact with web services. As the need to consume data grows, so does the number of API…&lt;/em&gt;github.com&lt;/a&gt;&lt;a href=&quot;https://github.com/tomasbasham/ratelimit&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/RazerM/ratelimiter&quot; title=&quot;https://github.com/RazerM/ratelimiter&quot;&gt;&lt;strong&gt;RazerM/ratelimiter&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Simple Python module providing rate limiting. This package provides the ratelimiter module, which ensures that an…&lt;/em&gt;github.com&lt;/a&gt;&lt;a href=&quot;https://github.com/RazerM/ratelimiter&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/alisaifee/flask-limiter&quot; title=&quot;https://github.com/alisaifee/flask-limiter&quot;&gt;&lt;strong&gt;alisaifee/flask-limiter&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Flask-Limiter provides rate limiting features to flask routes. It has support for a configurable backend for storage…&lt;/em&gt;github.com&lt;/a&gt;&lt;a href=&quot;https://github.com/alisaifee/flask-limiter&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/jsocol/django-ratelimit&quot; title=&quot;https://github.com/jsocol/django-ratelimit&quot;&gt;&lt;strong&gt;jsocol/django-ratelimit&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Cache-based rate-limiting for Django. Contribute to jsocol/django-ratelimit development by creating an account on…&lt;/em&gt;github.com&lt;/a&gt;&lt;a href=&quot;https://github.com/jsocol/django-ratelimit&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://www.django-rest-framework.org/api-guide/throttling/&quot; title=&quot;https://www.django-rest-framework.org/api-guide/throttling/&quot;&gt;&lt;strong&gt;Throttling&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;HTTP/1.1 420 Enhance Your Calm Twitter API rate limiting response Throttling is similar to permissions, in that it…&lt;/em&gt;www.django-rest-framework.org&lt;/a&gt;&lt;a href=&quot;https://www.django-rest-framework.org/api-guide/throttling/&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/jazzband/django-axes&quot; title=&quot;https://github.com/jazzband/django-axes&quot;&gt;&lt;strong&gt;jazzband/django-axes&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Axes is a very simple way for you to keep track of failed login attempts for your login and administration views. The…&lt;/em&gt;github.com&lt;/a&gt;&lt;a href=&quot;https://github.com/jazzband/django-axes&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/jazzband/django-defender&quot; title=&quot;https://github.com/jazzband/django-defender&quot;&gt;&lt;strong&gt;jazzband/django-defender&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;A simple Django reusable app that blocks people from brute forcing login attempts. The goal is to make this as fast as…&lt;/em&gt;github.com&lt;/a&gt;&lt;a href=&quot;https://github.com/jazzband/django-defender&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/brutasse/django-ratelimit-backend&quot; title=&quot;https://github.com/brutasse/django-ratelimit-backend&quot;&gt;&lt;strong&gt;brutasse/django-ratelimit-backend&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Rate-limit your login attempts at the authentication backend level. Login attempts are stored in the cache for 5…&lt;/em&gt;github.com&lt;/a&gt;&lt;a href=&quot;https://github.com/brutasse/django-ratelimit-backend&quot;&gt;&lt;/a&gt;* Make sure you keep track of IP address users are authenticating from, and limit users authenticating numerous times via the same IP address, thus preventing the same brute-force attack and also preventing man-in-the-middle attacks.&lt;/li&gt;
  &lt;li&gt;Always use the most secure protocol or mechanism to authenticate users. There is always a trade-off between security and usability, so beware!&lt;/li&gt;
  &lt;li&gt;Authentication tokens are not as secure as they seem to be, since stolen tokens are the key to everything. So, always use some sort of expiry, like refreshing the token every once in a while.
&lt;a href=&quot;https://auth0.com/blog/critical-vulnerabilities-in-json-web-token-libraries/&quot; title=&quot;https://auth0.com/blog/critical-vulnerabilities-in-json-web-token-libraries/&quot;&gt;&lt;strong&gt;Critical vulnerabilities in JSON Web Token libraries&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;TL;DR: If you are using node-jsonwebtoken, pyjwt, namshi/jose, php-jwt or jsjwt with asymmetric keys (RS256, RS384…&lt;/em&gt;auth0.com&lt;/a&gt;&lt;a href=&quot;https://auth0.com/blog/critical-vulnerabilities-in-json-web-token-libraries/&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://connect2id.com/products/nimbus-jose-jwt/vulnerabilities&quot; title=&quot;https://connect2id.com/products/nimbus-jose-jwt/vulnerabilities&quot;&gt;&lt;strong&gt;Common JWT security vulnerabilities and how to prevent them&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;The JSON Web Token has received a number of security reviews at the IETF and OIDF and is deemed sufficiently secure by…&lt;/em&gt;connect2id.com&lt;/a&gt;&lt;a href=&quot;https://connect2id.com/products/nimbus-jose-jwt/vulnerabilities&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://www.nccgroup.trust/uk/about-us/newsroom-and-events/blogs/2019/january/jwt-attack-walk-through/&quot; title=&quot;https://www.nccgroup.trust/uk/about-us/newsroom-and-events/blogs/2019/january/jwt-attack-walk-through/&quot;&gt;&lt;strong&gt;JWT Attack Walk-Through&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;There’s a well-known defect [1] with older versions of certain libraries where you can trick a JSON Web Token (JWT)…&lt;/em&gt;www.nccgroup.trust&lt;/a&gt;&lt;a href=&quot;https://www.nccgroup.trust/uk/about-us/newsroom-and-events/blogs/2019/january/jwt-attack-walk-through/&quot;&gt;&lt;/a&gt;* Use end-to-end encryption.
&lt;a href=&quot;https://github.com/pyca/cryptography&quot; title=&quot;https://github.com/pyca/cryptography&quot;&gt;&lt;strong&gt;pyca/cryptography&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;cryptography is a package which provides cryptographic recipes and primitives to Python developers. Our goal is for it…&lt;/em&gt;github.com&lt;/a&gt;&lt;a href=&quot;https://github.com/pyca/cryptography&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/dlitz/pycrypto&quot; title=&quot;https://github.com/dlitz/pycrypto&quot;&gt;&lt;strong&gt;dlitz/pycrypto&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;You can’t perform that action at this time. You signed in with another tab or window. You signed out in another tab or…&lt;/em&gt;github.com&lt;/a&gt;&lt;a href=&quot;https://github.com/dlitz/pycrypto&quot;&gt;&lt;/a&gt;* Use strong hashing mechanism that support better randomness and salt.&lt;/li&gt;
  &lt;li&gt;Firewalls are dumb. Use them, but don’t trust them fully. The same applies for other defensive mechanisms.&lt;/li&gt;
  &lt;li&gt;Misconfigurations are the root of all evil. Take it seriously!&lt;/li&gt;
  &lt;li&gt;Use captcha and account lockout mechanisms, which is also mentioned above.&lt;/li&gt;
  &lt;li&gt;Never permit weak passwords!&lt;/li&gt;
  &lt;li&gt;Never send authentication details in URL!&lt;/li&gt;
  &lt;li&gt;Always verify tokens, in terms of validity, expiry, etc!&lt;/li&gt;
  &lt;li&gt;Never reply with meaningful sensitive information. For example, replying whether a user exists or not to a forget password request will help the attacker enumerate users existing on your API or website. Ambiguous messages and &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/204&quot;&gt;204 No Content&lt;/a&gt; status code help prevent this issue.&lt;/li&gt;
  &lt;li&gt;Follow the guidelines in &lt;a href=&quot;https://cheatsheetseries.owasp.org/cheatsheets/Authentication_Cheat_Sheet.html&quot;&gt;OWASP Authentication Cheatsheet&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://cloud.google.com/endpoints/docs/openapi/when-why-api-key&quot;&gt;API keys are for projects, authentication is for users&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;Use multi-factor authentication (MFA), where possible, but also beware of SIM swap attack which may cause issues:
&lt;a href=&quot;https://www.wired.com/story/sim-swap-attack-defend-phone/&quot; title=&quot;https://www.wired.com/story/sim-swap-attack-defend-phone/&quot;&gt;&lt;strong&gt;How to Protect Your Phone Against a SIM Swap Attack&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Yes, remembering another PIN is a pain, especially when you’ll likely only need it every couple of years. But it’s…&lt;/em&gt;www.wired.com&lt;/a&gt;&lt;a href=&quot;https://www.wired.com/story/sim-swap-attack-defend-phone/&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://hackernoon.com/my-sim-swap-attack-how-i-almost-lost-dollar71k-and-how-to-prevent-it-tj39q3aju&quot; title=&quot;https://hackernoon.com/my-sim-swap-attack-how-i-almost-lost-dollar71k-and-how-to-prevent-it-tj39q3aju&quot;&gt;&lt;strong&gt;My SIM swap attack: How I almost lost $71K, and how to prevent it&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;On June 25th, I became a victim of SIM swapping, targeted along with dozens of other leaders in the blockchain…&lt;/em&gt;hackernoon.com&lt;/a&gt;&lt;a href=&quot;https://hackernoon.com/my-sim-swap-attack-how-i-almost-lost-dollar71k-and-how-to-prevent-it-tj39q3aju&quot;&gt;&lt;/a&gt;#### ✅ Authorization&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The second step is authorization, in which, the system decides whether the &lt;em&gt;authenticated user&lt;/em&gt; is authorized to access a resource. Imagine you have a website selling stuff. You don’t want each user to be able to see what other users have ordered, well, for privacy reasons. So the object of concern here is the order history and only the &lt;em&gt;owner&lt;/em&gt; of the order(s) can view it. If by some mechanism, other users can view each others’ order history, this makes your website insecure and untrustable.&lt;/p&gt;

&lt;p&gt;In terms of an API, you should disallow unauthorized access to resources via some authorization mechanism. As is practiced, it is best to authorize users based on their access to objects, and hence models. I have mentioned models, just because nowadays it is widely accepted to use an OxM (Object-to-X-Mapper, like ORM, OGM, ODM, etc.) to access your database tables, rows, nodes, relations, documents or the like. Since models are the single source of truth, it would be good to authorize users based on them, not the routes, since a users may access a route they are not authorized to, hence jeopardizing the security of your API. This may seem a little bit complicated, but just keep it mind that authorizing based on models are easier and safer. You can do both, but it easily gets messy and hard to manage.&lt;/p&gt;

&lt;p&gt;The usual method is to have a “&lt;strong&gt;User ↔ Role ↔ Permission&lt;/strong&gt;” set of models, in which authentication and user profile management is managed by the user object, and each user can have one or multiple role(s), which in turn, can have certain permissions granted to it. This is usually referred to as &lt;a href=&quot;https://en.wikipedia.org/wiki/Role-based_access_control&quot;&gt;role-based access controls (RBAC)&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Another method is to have a “&lt;strong&gt;User ↔ Group ↔ Permission&lt;/strong&gt;” set of models, in which a user belongs to one or more group(s) that may have a certain number of permissions. In this method, the group may have an arbitrary set of permissions, completely unrelated to the concept of its designation or role.&lt;/p&gt;

&lt;p&gt;The hardest part is when one has more than one role or belongs to more than one group. In this case, the best approach is to take advantage of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Principle_of_least_privilege&quot;&gt;principle of least privilege (PLoP)&lt;/a&gt;, meaning that the lowest permission(s) always win, or simply put, a user doesn’t need to have administrative access to view his order history. Also, make sure that you understand the &lt;a href=&quot;https://en.wikipedia.org/wiki/Object-capability_model&quot;&gt;object capability model&lt;/a&gt; to its fullest.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.beyondtrust.com/blog/entry/what-is-least-privilege&quot; title=&quot;https://www.beyondtrust.com/blog/entry/what-is-least-privilege&quot;&gt;&lt;strong&gt;What Is Least Privilege &amp;amp; Why Do You Need It? | BeyondTrust&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Least privilege is the concept and practice of restricting access rights for users, accounts, and computing processes…&lt;/em&gt;www.beyondtrust.com&lt;/a&gt;&lt;a href=&quot;https://www.beyondtrust.com/blog/entry/what-is-least-privilege&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/casbin/pycasbin&quot; title=&quot;https://github.com/casbin/pycasbin&quot;&gt;&lt;strong&gt;casbin/pycasbin&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;News: still worry about how to write the correct Casbin policy? Casbin online editor is coming to help! Try it at…&lt;/em&gt;github.com&lt;/a&gt;&lt;a href=&quot;https://github.com/casbin/pycasbin&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/YosaiProject/yosai&quot; title=&quot;https://github.com/YosaiProject/yosai&quot;&gt;&lt;strong&gt;YosaiProject/yosai&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Yosai is a “security framework” that features authentication, authorization, and session management from a common…&lt;/em&gt;github.com&lt;/a&gt;&lt;a href=&quot;https://github.com/YosaiProject/yosai&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/shonenada/flask-rbac&quot; title=&quot;https://github.com/shonenada/flask-rbac&quot;&gt;&lt;strong&gt;shonenada/flask-rbac&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;You can’t perform that action at this time. You signed in with another tab or window. You signed out in another tab or…&lt;/em&gt;github.com&lt;/a&gt;&lt;a href=&quot;https://github.com/shonenada/flask-rbac&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/dimagi/django-prbac&quot; title=&quot;https://github.com/dimagi/django-prbac&quot;&gt;&lt;strong&gt;dimagi/django-prbac&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;(Parameterized Role-Based Access Control) https://github.com/dimagi/django-prbac Role-based access control (RBAC) is…&lt;/em&gt;github.com&lt;/a&gt;&lt;a href=&quot;https://github.com/dimagi/django-prbac&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/klada/django-auth-rbac&quot; title=&quot;https://github.com/klada/django-auth-rbac&quot;&gt;&lt;strong&gt;klada/django-auth-rbac&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;An attempt of implementing role-based access control (ANSI/INCITS 359-2004) for Django Supported RBAC features: Core…&lt;/em&gt;github.com&lt;/a&gt;&lt;a href=&quot;https://github.com/klada/django-auth-rbac&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/django-guardian/django-guardian&quot; title=&quot;https://github.com/django-guardian/django-guardian&quot;&gt;&lt;strong&gt;django-guardian/django-guardian&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;django-guardian is an implementation of per object permissions [1] on top of Django’s authorization backend Online…&lt;/em&gt;github.com&lt;/a&gt;&lt;a href=&quot;https://github.com/django-guardian/django-guardian&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/sunscrapers/djoser&quot; title=&quot;https://github.com/sunscrapers/djoser&quot;&gt;&lt;strong&gt;sunscrapers/djoser&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;REST implementation of Django authentication system. djoser library provides a set of Django Rest Framework views to…&lt;/em&gt;github.com&lt;/a&gt;&lt;a href=&quot;https://github.com/sunscrapers/djoser&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/dfunckt/django-rules&quot; title=&quot;https://github.com/dfunckt/django-rules&quot;&gt;&lt;strong&gt;dfunckt/django-rules&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;rules is a tiny but powerful app providing object-level permissions to Django, without requiring a database. At its…&lt;/em&gt;github.com&lt;/a&gt;&lt;a href=&quot;https://github.com/dfunckt/django-rules&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/mgrouchy/django-stronghold&quot; title=&quot;https://github.com/mgrouchy/django-stronghold&quot;&gt;&lt;strong&gt;mgrouchy/django-stronghold&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Get inside your stronghold and make all your Django views default login_required Stronghold is a very small and easy to…&lt;/em&gt;github.com&lt;/a&gt;&lt;a href=&quot;https://github.com/mgrouchy/django-stronghold&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/jazzband/django-authority&quot; title=&quot;https://github.com/jazzband/django-authority&quot;&gt;&lt;strong&gt;jazzband/django-authority&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;This is a Django app for per-object-permissions that includes a bunch of helpers to create custom permission checks…&lt;/em&gt;github.com&lt;/a&gt;&lt;a href=&quot;https://github.com/jazzband/django-authority&quot;&gt;&lt;/a&gt;#### ✅ Access&lt;/p&gt;

&lt;p&gt;Sometimes you have the user authenticated and authorized to access a resource, but the resouce itself needs some special permissions, like delete permissions. Users may be able to view their order history, but may (or should) not be able to change them. This boils down to the specific object-level permissions one resource may have.&lt;/p&gt;

&lt;p&gt;So, authorization is the permission(s) the user has, while access is the permission(s) a resource needs, for the system to be able to grant access to it.&lt;/p&gt;

&lt;p&gt;This subtle difference is usually disregarded or misinterpreted, which leads to the topic of the current vulnerability I am talking about, broken object level authorization. From the user’s perspective, when they are in, they are in, but from the system’s and security perspective, this may not be the case. So, try to implement fine-grained access controls to restrict users and attackers from gaining access to your valuable resources.&lt;/p&gt;

&lt;h4 id=&quot;api22019-broken-authentication&quot;&gt;API2:2019-Broken Authentication&lt;/h4&gt;

&lt;p&gt;This topic is well discussed above, so if you want to know more about this vulnerability, make sure you read the first section, &lt;em&gt;API1:2019-Broken Object Level Authorization&lt;/em&gt;.&lt;/p&gt;

&lt;h4 id=&quot;api32019-excessive-data-exposure&quot;&gt;API3:2019-Excessive Data Exposure&lt;/h4&gt;

&lt;p&gt;It is considered a bad design decision, security-wise, to rely on client to filter out data returned by API, since an attacker can sit in between and hear all the communications (requests and responses) and sniff out sensitive information that should not be normally present.&lt;/p&gt;

&lt;p&gt;Always review all response data returned by all endpoints and try to validate all returned data against a schema to prevent exposure. Examples of this is returning all user objects data to the client, like password hashes and other sensitive data.&lt;/p&gt;

&lt;h4 id=&quot;api42019-lack-of-resources--rate-limiting&quot;&gt;API4:2019-Lack of Resources &amp;amp; Rate Limiting&lt;/h4&gt;

&lt;p&gt;Rate limiting is already discussed in &lt;em&gt;API1:2019-Broken Object Level Authorization&lt;/em&gt; to prevent brute-force attacks. It also applies to other system resources like CPU, memory, etc., which is always scarce, no matter how much you have and it can be easily saturated by overuse. Scarcity makes for different strategies for resource management. Rate limiting is one of those strategies. Another is to limit resource usage using something like &lt;a href=&quot;https://github.com/OWASP/CheatSheetSeries/blob/3a8134d792528a775142471b1cb14433b4fda3fb/cheatsheets/Docker_Security_Cheat_Sheet.md#rule-7---limit-resources-memory-cpu-file-descriptors-processes-restarts&quot;&gt;docker&lt;/a&gt; that can control resource usage.&lt;/p&gt;

&lt;p&gt;Relying on the client for data validation is a true mistake and should be prevented at all costs, meaning that client- and server-side validation should accompany each other. This also includes enforcing incoming data size to a specific amount.&lt;/p&gt;

&lt;p&gt;There are cases like zip bombs that can explode your resources on the server, so just verify compression ratio of compressed files before accepting and extracting the file:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://portswigger.net/daily-swig/ancient-zip-bomb-attack-given-new-lease-of-life&quot; title=&quot;https://portswigger.net/daily-swig/ancient-zip-bomb-attack-given-new-lease-of-life&quot;&gt;&lt;strong&gt;Ancient ZIP bomb attack given new lease of life&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;John Leyden 23 August 2019 at 15:46 UTC Decompression could give modern web apps a touch of the bends Researchers have…&lt;/em&gt;portswigger.net&lt;/a&gt;&lt;a href=&quot;https://portswigger.net/daily-swig/ancient-zip-bomb-attack-given-new-lease-of-life&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://www.vice.com/en_us/article/597vzx/the-most-clever-zip-bomb-ever-made-explodes-a-46mb-file-to-45-petabytes&quot; title=&quot;https://www.vice.com/en_us/article/597vzx/the-most-clever-zip-bomb-ever-made-explodes-a-46mb-file-to-45-petabytes&quot;&gt;&lt;strong&gt;The Most Clever ‘Zip Bomb’ Ever Made Explodes a 46MB File to 4.5 Petabytes&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;In the roughly three decades since the Zip file format debuted, compressed files have been subject to widespread…&lt;/em&gt;www.vice.com&lt;/a&gt;&lt;a href=&quot;https://www.vice.com/en_us/article/597vzx/the-most-clever-zip-bomb-ever-made-explodes-a-46mb-file-to-45-petabytes&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/danielmiessler/SecLists/tree/master/Payloads/Zip-Bombs&quot; title=&quot;https://github.com/danielmiessler/SecLists/tree/master/Payloads/Zip-Bombs&quot;&gt;&lt;strong&gt;danielmiessler/SecLists&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;SecLists is the security tester’s companion. It’s a collection of multiple types of lists used during security…&lt;/em&gt;github.com&lt;/a&gt;&lt;a href=&quot;https://github.com/danielmiessler/SecLists/tree/master/Payloads/Zip-Bombs&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/twbgc/sunzip&quot; title=&quot;https://github.com/twbgc/sunzip&quot;&gt;&lt;strong&gt;twbgc/sunzip&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;According to Cara Marie, an archive bomb a.k.a. A zip bomb is often employed to disable antivirus software, in order to…&lt;/em&gt;github.com&lt;/a&gt;&lt;a href=&quot;https://github.com/twbgc/sunzip&quot;&gt;&lt;/a&gt;#### API5:2019-Broken Function Level Authorization&lt;/p&gt;

&lt;p&gt;We have already discussed object level authorization in &lt;em&gt;API1:2019-Broken Object Level Authorization&lt;/em&gt;, which deal with unauthorized access to objects. Current vulnerability discusses a method by which the attacker is already authorized or is using a malicious input against an endpoint that requires little or no authorization, like anonymous users’ endpoints.&lt;/p&gt;

&lt;p&gt;A small change to a HTTP request method would make the endpoint vulnerable. For example, changing a GET request to POST would make the endpoint create or update a record with the same anonymous access rights. This also applies to the request URL, where you can simply change a /users to /admins and you’ll get all data relating to privileged admin users, which is horrible. Just keep in mind that almost everything in the request can be changed. Burp Suite is just one example, by which you can easily act as a proxy between client and the API and change the requests in between.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://support.portswigger.net/customer/portal/articles/1783101-how-to-use-burp-suite&quot; title=&quot;https://support.portswigger.net/customer/portal/articles/1783101-how-to-use-burp-suite&quot;&gt;&lt;strong&gt;How to Use Burp Suite&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Burp Suite is an integrated platform for performing security testing of web applications. It is designed to be used by…&lt;/em&gt;support.portswigger.net&lt;/a&gt;&lt;a href=&quot;https://support.portswigger.net/customer/portal/articles/1783101-how-to-use-burp-suite&quot;&gt;&lt;/a&gt;The best mechanism to prevent most of these vulnerabilities is to tighten enforcement of authorization rules, by denying everything by default and then explicitly giving access rights to specific roles for access to every function. This is also one of the most important topics in firewall configuration, in which the last rule is to deny all, in case that no rule matches against the criteria of the packet, is is denied and obviously not passed through.&lt;/p&gt;

&lt;h4 id=&quot;api62019-mass-assignment&quot;&gt;API6:2019-Mass Assignment&lt;/h4&gt;

&lt;p&gt;As said before, **NEVER EVER TRUST USER INPUT! **I just can’t put more emphasis on this advice. Certain things in database and workflow of the API is managed by user input, like a user profile or metadata passed along with an upload request. Binding users’ input parameters to exact objects without any validation and filtering is a recipe for disaster. Imagine an attacker sets a simple is_admin flag to True while sending a request to update a user’s profile. If not taken seriously, it would make the attacker an admin in the system right away. Just take input validation seriously, so that the next attacker or curious user not be able to update his account’s balance by updating it via a legitimate request to the system. Also be aware of some fields, like created and updated fields, which should almost always be internally handled and not passed from the user directly.&lt;/p&gt;

&lt;p&gt;Use white- and black-list feature to prevent some fields from being updated via requests.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://docs.djangoproject.com/en/2.2/ref/validators/&quot; title=&quot;https://docs.djangoproject.com/en/2.2/ref/validators/&quot;&gt;&lt;strong&gt;Validators | Django documentation | Django&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;A validator is a callable that takes a value and raises a if it doesn’t meet some criteria. Validators can be useful…&lt;/em&gt;docs.djangoproject.com&lt;/a&gt;&lt;a href=&quot;https://docs.djangoproject.com/en/2.2/ref/validators/&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://www.django-rest-framework.org/api-guide/permissions/&quot; title=&quot;https://www.django-rest-framework.org/api-guide/permissions/&quot;&gt;&lt;strong&gt;Permissions&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authentication or identification by itself is not usually sufficient to gain access to information or code. For that…&lt;/em&gt;www.django-rest-framework.org&lt;/a&gt;&lt;a href=&quot;https://www.django-rest-framework.org/api-guide/permissions/&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/dbrgn/drf-dynamic-fields&quot; title=&quot;https://github.com/dbrgn/drf-dynamic-fields&quot;&gt;&lt;strong&gt;dbrgn/drf-dynamic-fields&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;This package provides a mixin that allows the user to dynamically select only a subset of fields per resource. Official…&lt;/em&gt;github.com&lt;/a&gt;&lt;a href=&quot;https://github.com/dbrgn/drf-dynamic-fields&quot;&gt;&lt;/a&gt;#### API7:2019-Security Misconfiguration&lt;/p&gt;

&lt;p&gt;As I said above, misconfigurations, specially security misconfigurations, are the root of all evil. Taking security configurations as granted is a grave mistake. Since security is always considered as an afterthought, try to get rid of the temptation to forego implementing security recommendations, like encryption, hashing, rate-limiting, CORS, TLS, etc.&lt;/p&gt;

&lt;p&gt;There are some general pieces of advice:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Integrate hardening process in your workflow.&lt;/li&gt;
  &lt;li&gt;Regularly review and update configurations and packages on your projects and infrastructure. Always apply the latest security patches.&lt;/li&gt;
  &lt;li&gt;Use E2E encryption!&lt;/li&gt;
  &lt;li&gt;Try to integrate automated configuration analysis and vulnerability assessment in your workflow.&lt;/li&gt;
  &lt;li&gt;Never send stack traces produced by exceptions to the user (or potential attacker). Always validate the response against a schema.&lt;/li&gt;
  &lt;li&gt;Static analysis and linting will detect most of misconfigurations and bugs in the first place.
&lt;a href=&quot;https://docs.djangoproject.com/en/2.2/topics/security/&quot; title=&quot;https://docs.djangoproject.com/en/2.2/topics/security/&quot;&gt;&lt;strong&gt;Security in Django | Django documentation | Django&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Edit description&lt;/em&gt;docs.djangoproject.com&lt;/a&gt;&lt;a href=&quot;https://docs.djangoproject.com/en/2.2/topics/security/&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/mattupstate/flask-security&quot; title=&quot;https://github.com/mattupstate/flask-security&quot;&gt;&lt;strong&gt;mattupstate/flask-security&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;You can’t perform that action at this time. You signed in with another tab or window. You signed out in another tab or…&lt;/em&gt;github.com&lt;/a&gt;&lt;a href=&quot;https://github.com/mattupstate/flask-security&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://snyk.io/&quot; title=&quot;https://snyk.io/&quot;&gt;&lt;strong&gt;Snyk | Develop Fast. Stay Secure&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Enabling more than 400,000 developers to continuously find and fix vulnerabilities in open source libraries and…&lt;/em&gt;snyk.io&lt;/a&gt;&lt;a href=&quot;https://snyk.io/&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://www.sqreen.com/&quot; title=&quot;https://www.sqreen.com/&quot;&gt;&lt;strong&gt;Application Security Management Platform | Sqreen&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Ruby Node.js PHP Python Java Go .net $ echo “gem ‘sqreen’” » Gemfile $ bundle install $ echo “token: your token” &amp;gt;…&lt;/em&gt;www.sqreen.com&lt;/a&gt;&lt;a href=&quot;https://www.sqreen.com/&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://detectify.com/&quot; title=&quot;https://detectify.com/&quot;&gt;&lt;strong&gt;Detectify: Leading Website Vulnerability Scanner&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Detectify performs automated security tests on your web application and databases and scans your assets for…&lt;/em&gt;detectify.com&lt;/a&gt;&lt;a href=&quot;https://detectify.com/&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://arvan.cloud/&quot; title=&quot;https://arvan.cloud/&quot;&gt;&lt;strong&gt;ArvanCloud | Integrated Cloud Infrastructure&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;ArvanCloud offers integrated cloud services like CDN, Cloud DNS, Cloud Security, Cloud datacenter, Cloud storage, VoD…&lt;/em&gt;arvan.cloud&lt;/a&gt;&lt;a href=&quot;https://arvan.cloud/&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://semmle.com/&quot; title=&quot;https://semmle.com/&quot;&gt;&lt;strong&gt;Semmle - Code Analysis Platform for Securing Software&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Automating variant analysis for product security CodeQL is a code analysis engine for product security teams to quickly…&lt;/em&gt;semmle.com&lt;/a&gt;&lt;a href=&quot;https://semmle.com/&quot;&gt;&lt;/a&gt;#### API8:2019-Injection&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Injection, injection, injection! It is almost 2020 and we have have this injection issue! Neither OxMs nor any other pieces of software today can fully prevent it from being exploited. Well, there has been some advances in IDSes and cloud services to inspect and prevent such attacks, but it can still be exploited in the wide. Just keep in mind that NoSQL is also vulnerable to injection attacks.&lt;/p&gt;

&lt;p&gt;Nowadays working without having any relation to a third-party API is just not feasible anymore. Things like payment service providers, authentication providers and the like are all examples of such services. We, as developers, usually tend to think that when we pay for something, is it to be trusted, but sometimes reverse proves to be the case! So, I suggest you not to trust any data coming from external systems and APIs and validate them, too! For example, an attack on a third-party API may propagate to those using it in their APIs.&lt;/p&gt;

&lt;p&gt;These are some resources to learn more about ways to prevent injection:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://realpython.com/prevent-python-sql-injection/&quot; title=&quot;https://realpython.com/prevent-python-sql-injection/&quot;&gt;&lt;strong&gt;Preventing SQL Injection Attacks With Python - Real Python&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;SQL injection attacks are one of the most common web application security risks. In this step-by-step tutorial, you’ll…&lt;/em&gt;realpython.com&lt;/a&gt;&lt;a href=&quot;https://realpython.com/prevent-python-sql-injection/&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://blog.sqreen.com/preventing-sql-injections-in-python/&quot; title=&quot;https://blog.sqreen.com/preventing-sql-injections-in-python/&quot;&gt;&lt;strong&gt;Preventing SQL injections in Python (and other vulnerabilities) - Sqreen Blog&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Python is a wonderful language, ideal for beginners, and easy to scale up from starter projects to complex applications…&lt;/em&gt;blog.sqreen.com&lt;/a&gt;&lt;a href=&quot;https://blog.sqreen.com/preventing-sql-injections-in-python/&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://www.owasp.org/index.php/Reviewing_Code_for_OS_Injection&quot; title=&quot;https://www.owasp.org/index.php/Reviewing_Code_for_OS_Injection&quot;&gt;&lt;strong&gt;Reviewing Code for OS Injection&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Injection flaws allow attackers to pass malicious code through a web application to another subsystem. Depending on the…&lt;/em&gt;www.owasp.org&lt;/a&gt;&lt;a href=&quot;https://www.owasp.org/index.php/Reviewing_Code_for_OS_Injection&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/OWASP/CheatSheetSeries/blob/master/cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.md#python&quot; title=&quot;https://github.com/OWASP/CheatSheetSeries/blob/master/cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.md#python&quot;&gt;&lt;strong&gt;OWASP/CheatSheetSeries&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;XML eXternal Entity injection (XXE), which is now part of the OWASP Top 10 via the point A4, is a type of attack…&lt;/em&gt;github.com&lt;/a&gt;&lt;a href=&quot;https://github.com/OWASP/CheatSheetSeries/blob/master/cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.md#python&quot;&gt;&lt;/a&gt;#### API9:2019-Improper Assets Management&lt;/p&gt;

&lt;p&gt;APIs do not usually exist as a separate isolated entity, without having any relation or connection to its environment and outside world. They are literally living beings that sit there and listen to requests and eventually return a response. Yet they can be seen as assets to a company, making enough money for it to survive and grow. APIs and their belongings, like environments, accesses, …, should be seen as an inventory and shoud all be well-documented and accounted for. In turn, roles in the system and its data flow should also be documented. Security policies also need their own documentation.&lt;/p&gt;

&lt;p&gt;Versioning is an important part of product development, which is concretely seen as an important aspect of API development, where the routes themselves contain version information, e.g. /v1/products or /v2/consumers. Along the lifecycle of the API, some endpoints are become obsolete or deprecated, so they should be somehow decommissioned. Keeping track of these endpoints in older versions of the API help reduce the attack surface of the API, in case there is a gem for attackers hidden inside. At the same time, some vulnerabilities are found in the new endpoints which needs to be ported the old ones. This specific backports should be taken seriously, by QAs, reviewers and testers and be labeled separately in any project management or ticketing solution to provide more visibility into the matter.&lt;/p&gt;

&lt;h4 id=&quot;api102019-insufficient-logging--monitoring&quot;&gt;API10:2019-Insufficient Logging &amp;amp; Monitoring&lt;/h4&gt;

&lt;p&gt;With enough logging and monitoring all issues can be unearthed and examined before causing any severe damage to the system (API) and credibility of the company.&lt;/p&gt;

&lt;p&gt;It is really easy to saturate and overwhelm the log server with useless log messages. In terms of security, focus on special log messages, called security events, like failed authentication attempts, denied accesses and input validation errors and try to log enough data to help uncover the issue. Logs are considered as sensitive data, so handle it with care!&lt;/p&gt;

&lt;p&gt;Implement and configure a monitoring solution to continuously monitor every asset in your system and use a Security Information and Event Management (SIEM) solution to aggregate logs and provide meaningful insights out of them.&lt;/p&gt;

&lt;p&gt;Last but not least, do not stick with the default dashboards, customize them to show important security events first.&lt;/p&gt;

&lt;p&gt;These are some recommendations, but you know best!&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://cheatsheetseries.owasp.org/cheatsheets/Logging_Cheat_Sheet.html&quot; title=&quot;https://cheatsheetseries.owasp.org/cheatsheets/Logging_Cheat_Sheet.html&quot;&gt;&lt;strong&gt;Logging&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;This cheat sheet is focused on providing developers with concentrated guidance on building application logging…&lt;/em&gt;cheatsheetseries.owasp.org&lt;/a&gt;&lt;a href=&quot;https://cheatsheetseries.owasp.org/cheatsheets/Logging_Cheat_Sheet.html&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://grafana.com/&quot; title=&quot;https://grafana.com/&quot;&gt;&lt;strong&gt;Grafana: The open observability platform&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;The open observability platform Grafana is the open source analytics &amp;amp; monitoring solution for every database Get…&lt;/em&gt;grafana.com&lt;/a&gt;&lt;a href=&quot;https://grafana.com/&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://www.elastic.co/what-is/elk-stack&quot; title=&quot;https://www.elastic.co/what-is/elk-stack&quot;&gt;&lt;strong&gt;ELK Stack: Elasticsearch, Logstash, Kibana | Elastic&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;What is the ELK Stack? The ELK Stack is an acronym for a combination of three widely used open source projects…&lt;/em&gt;www.elastic.co&lt;/a&gt;&lt;a href=&quot;https://www.elastic.co/what-is/elk-stack&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://www.datadoghq.com/&quot; title=&quot;https://www.datadoghq.com/&quot;&gt;&lt;strong&gt;Cloud Monitoring as a Service | Datadog&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;See metrics from all of your apps, tools &amp;amp; services in one place with Datadog’s cloud monitoring as a service solution…&lt;/em&gt;www.datadoghq.com&lt;/a&gt;&lt;a href=&quot;https://www.datadoghq.com/&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://www.esecurityplanet.com/products/top-siem-products.html&quot; title=&quot;https://www.esecurityplanet.com/products/top-siem-products.html&quot;&gt;&lt;strong&gt;Top SIEM Products&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Security Information and Event Management (SIEM) is a key enterprise security technology, with the ability to tie…&lt;/em&gt;www.esecurityplanet.com&lt;/a&gt;&lt;a href=&quot;https://www.esecurityplanet.com/products/top-siem-products.html&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://www.capterra.com/siem-software/&quot; title=&quot;https://www.capterra.com/siem-software/&quot;&gt;&lt;strong&gt;Best SIEM Software | 2019 Reviews of the Most Popular Tools &amp;amp; Systems&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Find and compare SIEM software. Free, interactive tool to quickly narrow your choices and contact multiple vendors.&lt;/em&gt;www.capterra.com&lt;/a&gt;&lt;a href=&quot;https://www.capterra.com/siem-software/&quot;&gt;&lt;/a&gt;#### Conclusion&lt;/p&gt;

&lt;p&gt;What I’ve tried to achieve in this long article was to inform you of the Top 10 list of vulnerabilities found in today’s APIs that threatens their existence. I’ve mentioned many Python packages, cheatsheets, related resources and software needed for the job. But the developer always knows best. Yeah, common sense can alleviate most of these.&lt;/p&gt;

&lt;p&gt;Try to take advice from experts in the field, specially those contributed to the making of the Top 10 list and &lt;strong&gt;NEVER EVER TRUST USER INPUT!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Cover image credits: &lt;a href=&quot;https://github.com/OWASP/API-Security/blob/develop/2019/en/dist/owasp-api-security-top-10.pdf&quot;&gt;OWASP API Security Top 10 2019 PDF cover&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">In my previous article about secure code review and penetration testing of Node.js and JavaScript apps, I tried to give the reader an introduction to the old, but gold, OWASP Code Review Project and the OWASP Top 10 Project and to mention the tools of the trade using the simplest approach possible.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://mostafa.dev/img/1*ALeWhQ2N6rbL3TPAtmKeRQ.png" /><media:content medium="image" url="https://mostafa.dev/img/1*ALeWhQ2N6rbL3TPAtmKeRQ.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Integrating k6 with Apache Kafka</title><link href="https://mostafa.dev/blog/integrating-k6-with-apache-kafka" rel="alternate" type="text/html" title="Integrating k6 with Apache Kafka" /><published>2019-11-22T00:00:00+01:00</published><updated>2019-11-22T00:00:00+01:00</updated><id>https://mostafa.dev/blog/integrating-k6-with-apache-kafka</id><content type="html" xml:base="https://mostafa.dev/blog/integrating-k6-with-apache-kafka">&lt;p&gt;Undoubtedly, &lt;a href=&quot;https://kafka.apache.org/&quot;&gt;Apache Kafka&lt;/a&gt; is one of the most prominent pieces of software existing in today’s distributed architectures, from cloud-providers supporting it to on-premise setups. It can be used to store and process millions of messages per second, so it makes it a perfect fit for distributed real-time data processing solutions. Although it provides very advanced features like stream-processing and horizontal scalability, it is very easy to use: you just have to send your messages to it (produce) and later pick them up (consume) for further processing. It has all the features you need from a modern distributed data store: communication interface, persistence, scalability, streaming and management. Once developed at LinkedIn for data processing, later donated to the Apache Software Foundation. I do highly recommend you to have a look at its &lt;a href=&quot;https://kafka.apache.org/documentation/&quot;&gt;documentation&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://k6.io/&quot;&gt;k6&lt;/a&gt; is a free and open-source load testing tool built with unit-testing in mind, but for performance. It can produce hundreds of messages per second, as a result of testing a system or platform. These messages can be sent to a number of different destinations, like a JSON file or Apache Kafka, which works out of the box with zero dependency, other than the Apache Kafka setup itself.&lt;/p&gt;

&lt;p&gt;To be able to send messages from k6 to Apache Kafka, we’d go with &lt;a href=&quot;https://kafka.apache.org/documentation/#quickstart&quot;&gt;a very simple setup&lt;/a&gt;, with only one instance. In our scenario, k6 would act as a simple producer of JSON messages and we’ll try to consume message on terminal, using the built-in simple kafka consumer. Here I will use the official binary provided by Apache and would leave the docker setup up to you to try. To give you a clue, using Lenses.io’s &lt;a href=&quot;https://github.com/lensesio/fast-data-dev&quot;&gt;fast-data-dev&lt;/a&gt;, you can have a complete Docker environment with Kafka, ZooKeeper, Schema Registry, Kafka-Connect, Landoop Tools and more than 20 connectors in an easy to use package.&lt;/p&gt;

&lt;p&gt;Since we’re using the binary package, no special installation is needed, and you can directly invoke the binary from the command line. I have used &lt;a href=&quot;https://www.debian.org/&quot;&gt;Debian GNU/Linux&lt;/a&gt; 10.2 to run these commands. Simply follow the instructions below:&lt;/p&gt;

&lt;h3 id=&quot;1-download-and-extract-apache-kafka-platform-binaries&quot;&gt;1. Download and extract Apache Kafka platform binaries&lt;/h3&gt;

&lt;p&gt;The current version as of this writing is 2.3.0, but you can choose your own desired version.&lt;/p&gt;

&lt;p&gt;$ &lt;strong&gt;wget **&lt;a href=&quot;http://apache.mirrors.spacedump.net/kafka/2.3.0/kafka_2.12-2.3.0.tgz&quot;&gt;**http://apache.mirrors.spacedump.net/kafka/2.3.0/kafka_2.12-2.3.0.tgz**&lt;/a&gt;&lt;br /&gt;
$ **tar xvf kafka_2.12-2.3.0.tgz&lt;/strong&gt;&lt;br /&gt;
$ &lt;strong&gt;cd kafka_2.12-2.3.0&lt;/strong&gt;### 2. Start Apache ZooKeeper and Kafka&lt;/p&gt;

&lt;p&gt;As you can see, when you start the ZooKeeper, it will start listening on all interfaces (0.0.0.0) on port &lt;strong&gt;2181&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;$ &lt;strong&gt;bin/zookeeper-server-start.sh config/zookeeper.properties&lt;/strong&gt;Now start Kafka server in a new terminal. It will connect to your local ZooKeeper instance on port 2181 and will start listening for new connections on port &lt;strong&gt;9092&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;$ &lt;strong&gt;bin/kafka-server-start.sh config/server.properties&lt;/strong&gt;&lt;br /&gt;
[2019-11-15 12:43:54,672] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)&lt;br /&gt;
…&lt;br /&gt;
[2019-11-15 12:43:55,366] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)&lt;br /&gt;
…&lt;br /&gt;
[2019-11-15 12:43:55,666] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)### 3. Create a topic to send k6 data to&lt;/p&gt;

&lt;p&gt;On another terminal, create a topic, for example &lt;em&gt;k6-output&lt;/em&gt;, to receive k6 messages on. This topic would be a single partition topic with no replication.&lt;/p&gt;

&lt;p&gt;$ &lt;strong&gt;bin/kafka-topics.sh –create –bootstrap-server localhost:9092 –replication-factor 1 –partitions 1 –topic k6-output&lt;/strong&gt;### 4. Start k6 with Kafka output&lt;/p&gt;

&lt;p&gt;Using the following script in a file named &lt;em&gt;scenario.js&lt;/em&gt;, we’ll start k6 to send its output to Kafka:&lt;/p&gt;

&lt;p&gt;$ &lt;strong&gt;k6 run –logformat=raw –out kafka=brokers=localhost:9092,topic=k6-output,format=json scenario.js&lt;/strong&gt;### 5. Consume message on a terminal&lt;/p&gt;

&lt;p&gt;To view message of k6 output on your terminal, use the following built-in consumer:&lt;/p&gt;

&lt;p&gt;$ &lt;strong&gt;bin/kafka-console-consumer.sh –bootstrap-server localhost:9092 –topic k6-output&lt;/strong&gt;As you can see, we’ve sent our message with JSON format to Kafka, so you can write a simple JSON consumer in your own desired programming language (e.g. Python) and start consuming and using the data provided by k6 to Kafka. There are other possibilities, like using platforms that can import or consume data from Apache Kafka, like &lt;a href=&quot;https://spark.apache.org/&quot;&gt;Apache Spark&lt;/a&gt; or Kafka Connect from &lt;a href=&quot;https://www.confluent.io/product/confluent-platform/&quot;&gt;Confluent Platform&lt;/a&gt;, to name a few.&lt;/p&gt;

&lt;p&gt;You can also use visualization platforms that has support for Kafka as input. I recommend reading the following articles about it:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.elastic.co/blog/just-enough-kafka-for-the-elastic-stack-part1&quot;&gt;&lt;strong&gt;Just Enough Kafka for the Elastic Stack, Part 1&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.elastic.co/blog/just-enough-kafka-for-the-elastic-stack-part2&quot;&gt;&lt;strong&gt;Just Enough Kafka for the Elastic Stack, Part 2&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://grafana.com/blog/2019/07/22/guest-blog-post-how-the-k6-load-testing-tool-is-leveraging-grafana/&quot;&gt;&lt;strong&gt;Guest Blog Post: How the k6 Load Testing Tool Is Leveraging Grafana&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I hope you’ve found this article helpful and were able to send your k6 output to Apache Kafka, an industry-proven technology.&lt;/p&gt;

&lt;p&gt;If you have any suggestions or comments, I really like to hear from you.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Originally published at &lt;a href=&quot;https://blog.loadimpact.com/integrating-k6-with-apache-kafka&quot;&gt;https://blog.loadimpact.com&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">Undoubtedly, Apache Kafka is one of the most prominent pieces of software existing in today’s distributed architectures, from cloud-providers supporting it to on-premise setups. It can be used to store and process millions of messages per second, so it makes it a perfect fit for distributed real-time data processing solutions. Although it provides very advanced features like stream-processing and horizontal scalability, it is very easy to use: you just have to send your messages to it (produce) and later pick them up (consume) for further processing. It has all the features you need from a modern distributed data store: communication interface, persistence, scalability, streaming and management. Once developed at LinkedIn for data processing, later donated to the Apache Software Foundation. I do highly recommend you to have a look at its documentation.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://mostafa.dev/img/0*TDOUgQUzVFGShAHO.png" /><media:content medium="image" url="https://mostafa.dev/img/0*TDOUgQUzVFGShAHO.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Migration of Old Projects to Python 3</title><link href="https://mostafa.dev/blog/migration-of-old-projects-to-python-3" rel="alternate" type="text/html" title="Migration of Old Projects to Python 3" /><published>2019-08-03T00:00:00+02:00</published><updated>2019-08-03T00:00:00+02:00</updated><id>https://mostafa.dev/blog/migration-of-old-projects-to-python-3</id><content type="html" xml:base="https://mostafa.dev/blog/migration-of-old-projects-to-python-3">&lt;p&gt;A while ago I’ve self-assigned the daunting task of migrating an ancient API project written in Python 2.7 and Django to the latest stable Python 3.7 and Django 2.2. What at first seemed to be a piece of cake, turned out to be a Hydra, the multi-headed dragon, with its dependencies acting like an octopus.&lt;/p&gt;

&lt;p&gt;I should admit that it was no easy task. I remember days I was banging my head to get that tiny fix to work as expected. But it all went well, hopefully, and I was able to migrate the project into an almost stable piece of code that just works.&lt;/p&gt;

&lt;p&gt;As far as I know, the &lt;a href=&quot;https://pythonclock.org/&quot;&gt;countdown&lt;/a&gt; of sunsetting of Python 2.7 is nearer than it appears. It sadly means that the version 2 flavor of Python won’t be maintained beyond 1st January 2020, which is inevitable. This date would be the official end of life of Python 2. This calls to an action to try to avoid it in the very near future for all companies using it.&lt;/p&gt;

&lt;p&gt;The maintainers and the community worked hard to make everything compatible with the new Python 3 counterpart. The &lt;a href=&quot;http://py3readiness.org/&quot;&gt;readiness score&lt;/a&gt; of Python 3 packages compatibility is eye-catching and a growing number of packages already has support for both version, while some completely switched to Python 3, specially those libraries written for newly widespread platforms, like shiny new database drivers. There is a &lt;a href=&quot;https://python3statement.org/&quot;&gt;timeline&lt;/a&gt; for many important packages that will Python 3, and would drop support for the old Python 2.&lt;/p&gt;

&lt;p&gt;Writing code against both flavors of Python and maintaining that code-base is really hard, since the &lt;a href=&quot;https://galorath.com/software-maintenance-costs/&quot;&gt;maintenance cost&lt;/a&gt; is high. It is even more costly when you want to develop a library, since actual projects can stick with a specific flavor. There is always a trade-off between choosing the old version and having the latest greatest features. This being said, so much can be ported to the old version, and eventually portability becomes an issue itself. For almost every single package you find in Python 3, either in the standard library or in third-parties, there is a backport to Python 2, but &lt;a href=&quot;https://www.reddit.com/r/Python/comments/41wl2t/libraries_that_support_python_3x_but_not_27/&quot;&gt;this doesn’t hold true for the new features of Python 3&lt;/a&gt;. Two simple example would be the very great &lt;a href=&quot;https://docs.python.org/3/library/asyncio.html&quot;&gt;asyncio&lt;/a&gt; and &lt;a href=&quot;https://aiohttp.readthedocs.io/en/stable/&quot;&gt;aiohttp&lt;/a&gt; libraries.&lt;/p&gt;

&lt;p&gt;As I said above, migration is no easy task, meaning that you cannot just change your interpreter version in your configuration file and headers and expect it to work right away. You should plan, analyze and iterate through the code-base to have everything migrated. I’ll explain each in greater details.&lt;/p&gt;

&lt;p&gt;In the middle of doing this, I felt the need to have some search mechanism that can understand the structure of the Python code, so that I’ll be able to search inside imports in each file in the project, in order to able to understand where each module is actually used. So I’ve written a script that maps all python files inside the project to a nested dictionary, with its values being imports in that specific file. It then gives me the ability to search with a XPath-like syntax (via &lt;a href=&quot;https://pypi.org/project/dpath/&quot;&gt;dpath&lt;/a&gt;). I’ll make it available soon as FOSS. It’s called “&lt;em&gt;Algae&lt;/em&gt;”.&lt;/p&gt;

&lt;h3 id=&quot;methodology&quot;&gt;Methodology&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/img/1*p6cylSLFAjRPht0oIuvWJA.png&quot; alt=&quot;&quot; /&gt;Planning involves knowing the extent you wish your project to be updated. Sometimes you want to stick with an LTS version of some library and other times you want the latest cutting-edge features. This trade-off of stability versus trendiness is what to look for while planning for the migration.&lt;/p&gt;

&lt;p&gt;This planning should also take into account the business side, although the focus of this article is on the engineering complications. Some changes should be organized and changed with the help of different departments. Otherwise it just won’t work. You’re going to deliver the same value or more to the customer, while decreasing technical debt and maintenance costs.&lt;/p&gt;

&lt;p&gt;Analysis is the next step. You probably are already familiar with the project you are working on, or at least have worked on some parts of it and you know what it does. Analysis is to know what to keep, update or get rid of. Sometimes the project has grown organically and you no longer use some parts of it, like old API versions. Now is a good time to rethink. Sometimes a rewrite would be a more viable option, since the code-base is so messy that you no longer want to touch it. Other times, polishing and migration of the same code-base is easier and less costly. Whichever path you take would reveal your next moves.&lt;/p&gt;

&lt;p&gt;Some changes include update to the backend services, like an update to a database driver that no longer supports outdated versions of that database. Some would break the tests, undoubtedly. This is what to expect while analyzing your code-base. You can’t just update the code and expect it to work without touching anything else. You have to think about it thoroughly.&lt;/p&gt;

&lt;p&gt;Iteration is the actual work you want to do to ensure that you have an up-to-date application. It is called iteration, since you cannot move everything all at once. It is truly infeasible. Just don’t!&lt;/p&gt;

&lt;p&gt;On each iteration, you actually take action by changing each part meticulously. Some parts are easy to change and require minimal amount of work, like updating small functional dependencies. Yet there are parts that require a lot of effort and time to change and test.&lt;/p&gt;

&lt;h3 id=&quot;recommendations&quot;&gt;Recommendations&lt;/h3&gt;

&lt;h4 id=&quot;1-use-branching-to-isolate-changes&quot;&gt;1. Use branching to isolate changes&lt;/h4&gt;

&lt;p&gt;Each change should go into a new branch, e.g. git branch. This is to decrease clutter and friction with other parts. This would help narrow down the scope of change and would help you easily revert breaking or malfunctioning changes.&lt;/p&gt;

&lt;p&gt;It is okay to build on top of the same change by sub-branching from the same branch you used to work on, and which is tested and worked as expected. You cannot push people to review your code changes, although being subjective, except the company’s future depends on it.&lt;/p&gt;

&lt;h4 id=&quot;2-upgrade-everything-to-latest-version-supported-by-python-27&quot;&gt;2. Upgrade everything to latest version supported by Python 2.7&lt;/h4&gt;

&lt;p&gt;The first iteration, besides version control and branching, would be to update dependencies to the latest version supported by Python 2.7. This helps find some bugs and alleviate many headaches afterwards. For example, the latest long-term support (LTS) version of Django supporting Python 2.7 is &lt;a href=&quot;https://upgradedjango.com/1.11/&quot;&gt;1.11.x&lt;/a&gt; and of Django REST Framework is &lt;a href=&quot;https://www.django-rest-framework.org/community/release-notes/#39x-series&quot;&gt;3.9.x&lt;/a&gt;. This means that the official support for these libraries on Python 2.7 is dropped and no longer available. It’s safe to say that upgrading to these versions has the least friction, unless your existing Django and DRF is ancient and unsupported.&lt;/p&gt;

&lt;p&gt;Sometimes the changes in each version of Django and/or DRF is not backward compatible, so you have to keep an eye on Release Notes and Changelogs to adapt your code to the new changes.&lt;/p&gt;

&lt;h4 id=&quot;3-monitor-tests-continuous-integration-and-coverage&quot;&gt;3. Monitor tests, Continuous Integration and coverage&lt;/h4&gt;

&lt;p&gt;In this step, you should ensure that your tests pass and your coverage is not decreased dramatically. One of the biggest technical debts are not having enough tests, which would come to surface with users complaining about failures and developers seeing flaky test runs while updating code.&lt;/p&gt;

&lt;p&gt;If that’s the case, consider writing more tests and invest more on CI workflows and pipelines. Of investment, I don’t necessarily mean money. Sometimes correcting a broken pipeline would help alleviate many issues in the future.&lt;/p&gt;

&lt;p&gt;The next step is to monitor your test results to see if there are errors and warnings related to your code. Yes, I’ve seen tests pass, having many errors and warnings that are simply ignored. Test runner should be chosen wisely. Although the “unittest” standard library module is feature-rich, I do prefer “pytest” as a more flexible and extendable counterpart. This obviously doesn’t stop you from choosing your preferred test suite or even writing your own.&lt;/p&gt;

&lt;p&gt;Your tests should not only include unittests. Integration, E2E, acceptance and performance test are just some of all the available test methodologies.&lt;/p&gt;

&lt;h4 id=&quot;4-run-2to3-on-your-code-base&quot;&gt;4. Run 2to3 on your code-base&lt;/h4&gt;

&lt;p&gt;After upgrading to the latest versions supported on Python 2.7 and testing to see if everything’s in order, now is the time to run the 2to3 tool on your code-base. This is a tool provided as part of the Python standard library to read the Python 2.x source code and transform them into a valid Python 3.x source code, through the so-called &lt;a href=&quot;https://docs.python.org/3.7/library/2to3.html#fixers&quot;&gt;&lt;em&gt;fixers&lt;/em&gt;&lt;/a&gt;. Fixers are changes to the syntax and semantics of the source code from Python 2.x to 3.x. For example, in Python 2.x, it is not necessary to have parenthesis around the print function, but such functions no longer exist in Python 3.x. So the *print *fixer converts print function to print() all over your source code. Test again and again and make sure not to mess things up by not using branching.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Update:&lt;/em&gt; a &lt;a href=&quot;https://www.reddit.com/r/Python/comments/clugax/migration_of_old_projects_to_python_3_how_to_deal/evyutsc?utm_source=share&amp;amp;utm_medium=web2x&quot;&gt;user on reddit commented&lt;/a&gt; that we could use &lt;a href=&quot;https://pypi.org/project/modernize/&quot;&gt;modernize&lt;/a&gt; instead, to be able to spot more conversion errors, specially Unicode-related ones.&lt;/p&gt;

&lt;h4 id=&quot;5-change-your-interpreter-and-package-manager&quot;&gt;5. Change your interpreter and package manager&lt;/h4&gt;

&lt;p&gt;Now is the time to change your Python version to 3.7. Usually this is done by either installing it using a package manager, like APT, or just changing your Dockerfile FROM statement to include python:3.7.&lt;/p&gt;

&lt;p&gt;This is the trickiest part, since many tests may fail, due to incompatible requirements and dependencies.&lt;/p&gt;

&lt;p&gt;I do also recommend you to upgrade your package manager, pip, to the latest version.&lt;/p&gt;

&lt;h4 id=&quot;6-upgrade-your-dependencies&quot;&gt;6. Upgrade your dependencies&lt;/h4&gt;

&lt;p&gt;It is a good idea to check your dependencies before upgrade by running &lt;a href=&quot;https://pypi.org/project/pipdeptree/&quot;&gt;pipdeptree&lt;/a&gt; on the requirements.txt file to detect circular and conflicting dependencies. The next best tool is the &lt;a href=&quot;https://pypi.org/project/pur/&quot;&gt;pip-update-requirements&lt;/a&gt; that helps you upgrade all dependencies in the requirements.txt file.&lt;/p&gt;

&lt;p&gt;Some dependencies are not easily upgradable, either because they are no longer supported anymore, specially on Python 3.x, or newer libraries have replaced them. For example, &lt;a href=&quot;https://pypi.org/project/pycassa/&quot;&gt;pycassa&lt;/a&gt; is an old database driver for Cassandra supporting only Python 2.x, with &lt;a href=&quot;https://github.com/pycassa/pycassa&quot;&gt;its last commit on 17 January 2017&lt;/a&gt;, which only supports Thrift protocol and there is no CQL support. But the official &lt;a href=&quot;https://pypi.org/project/cassandra-driver/&quot;&gt;DataStax Python Driver&lt;/a&gt; replaced it deliberately supporting 2.7 and 3.x, which is easier to use and has more features and also is based on CQL.&lt;/p&gt;

&lt;p&gt;Some other libraries have different issues. For example, python-social-auth package is deprecated and you should upgrade all your dependencies to social-auth-core and social-auth-app-django, in which you have to change many parts of the settings.py and your imports.&lt;/p&gt;

&lt;p&gt;Some other libraries are replaced with better counterparts. For example, the python-memcached library has many other more up-to-date alternatives like pymemcache or pylibmc.&lt;/p&gt;

&lt;h4 id=&quot;7-upgrade-django-and-drf-to-latest-version&quot;&gt;7. Upgrade Django and DRF to latest version&lt;/h4&gt;

&lt;p&gt;The Django &lt;a href=&quot;https://docs.djangoproject.com/en/dev/internals/release-process/&quot;&gt;release process&lt;/a&gt; is a good resource for knowing what to use and when to deprecate and get rid of old versions. The release roadmap on &lt;a href=&quot;https://www.djangoproject.com/download/&quot;&gt;Django download page&lt;/a&gt; will give you a very quick view into the lifetime of each version.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/1*aI2NZdsLaxzzu_fT8-0FNA.png&quot; alt=&quot;&quot; /&gt;Credits: &lt;a href=&quot;https://www.djangoproject.com/download/&quot;&gt;https://www.djangoproject.com/download/&lt;/a&gt;As of now, the latest LTS version of Django that only supports Python 3.x is 2.2.x and the latest version of DRF is 3.10.x.&lt;/p&gt;

&lt;p&gt;If you could eventually pass step 6, you can almost easily upgrade these versions and test if everything holds together.&lt;/p&gt;

&lt;p&gt;Upgrading Django from 1.11.x to 2.x is a lot more painful than I thought it would be and it needs more time to be invested to get everything work correctly. There are removals, deprecations and changes that you should be aware of, to not break your system. Consider doing the upgrade step by step, otherwise you’ll be in big trouble hunting multiple unrelated bugs and the whole process would quickly become exhausting.&lt;/p&gt;

&lt;p&gt;I hope you got an overview of what to expect while upgrading your Django and DRF application to the latest versions supported by Python 3.7. If you have any questions, comments or improvements, I’ll be really glad to hear them.&lt;/p&gt;</content><author><name></name></author><summary type="html">A while ago I’ve self-assigned the daunting task of migrating an ancient API project written in Python 2.7 and Django to the latest stable Python 3.7 and Django 2.2. What at first seemed to be a piece of cake, turned out to be a Hydra, the multi-headed dragon, with its dependencies acting like an octopus.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://mostafa.dev/img/1*S_BW9ZtWNkv502m_E5Ij2Q.png" /><media:content medium="image" url="https://mostafa.dev/img/1*S_BW9ZtWNkv502m_E5Ij2Q.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Employment Contract</title><link href="https://mostafa.dev/blog/employment-contract" rel="alternate" type="text/html" title="Employment Contract" /><published>2019-07-16T00:00:00+02:00</published><updated>2019-07-16T00:00:00+02:00</updated><id>https://mostafa.dev/blog/employment-contract</id><content type="html" xml:base="https://mostafa.dev/blog/employment-contract">&lt;p&gt;&lt;strong&gt;&lt;em&gt;Disclaimer:&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;I am not an attorney, a lawyer or an advocate whatsoever, so seek the help of a professional on your case before signing anything.&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;I tried my best to be as anonymous as possible about the attributions and references in this article and I strongly deny any attributions.&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;*I try to be as fair and as informative as possible to both parties, and I take no responsibility on any of the views expressed in this article. *USE THEM AT YOUR OWN RISK!&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;Views expressed in this articles are solely those of the author.&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;Always try to seek clarification if you don’t understand a clause.&lt;/em&gt;&lt;/strong&gt;
    &lt;h3 id=&quot;introduction&quot;&gt;Introduction&lt;/h3&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There are, &lt;em&gt;at least&lt;/em&gt;, two sides (or parties) to each employment contract. The employer who gives you an offer after &lt;em&gt;careful&lt;/em&gt; consideration and the employee, that you are, who want to weigh your options and eventually negotiate, sign or reject the contract (or the offer) altogether.&lt;/p&gt;

&lt;p&gt;So far, I haven’t seen any firm, sound and perfect employment contract. There are either some minor or major flaws. It seems that no professional have had any chance to review them. It sometimes seems epidemic to me to face contracts, which are flawed in their basic clauses.&lt;/p&gt;

&lt;p&gt;Some of them try to use a &lt;em&gt;friendly&lt;/em&gt; voice, some are &lt;em&gt;aggressive&lt;/em&gt; and some are &lt;em&gt;cryptic&lt;/em&gt;. Those who talk friendly are mostly the ones their offer is quickly accepted, since friendly manners can be seen in their legal documents. The aggressive ones are those who try to stop you from practicing your rights and try to be as strict as possible, &lt;em&gt;which they can’t&lt;/em&gt;. The cryptics try to hide behind the misunderstood and misinterpreted laws, rules and regulations.&lt;/p&gt;

&lt;p&gt;It seems like the employer and the employee are on different pages. In order to show them the light, I’ll try to explain how to approach a contract and how to eventually negotiate, sign or reject it. It’s a live document and I’ll try to update it as much as I learn more about the laws, rules and regulations.&lt;/p&gt;

&lt;p&gt;An employment contract, &lt;em&gt;“contract”&lt;/em&gt; from now on, is a set of terms, rules, conditions, laws and regulations which allows the employer and employee to know their rights and responsibilities and try to work together, as set in the contract. The contact is almost always bilateral, meaning both parties have responsibilities and obligations. This bilateral contract lets them seek the practice of law — and sometimes force in worst cases — to deal with issues arising from any party not conforming to the contract.&lt;/p&gt;

&lt;p&gt;I presume that you have passed all the interviews, tests, on-site, off-site, online and everything else and you’ve been offered a contract, so you are thinking: &lt;em&gt;“now what?”&lt;/em&gt;. What I am trying to do is to answer your “now what?” question.&lt;/p&gt;

&lt;p&gt;A contract usually includes some or most of the following topics, which I will try to explain in greater detail hereafter. It is going to be a long text, which obviously I do recommend you to read, but otherwise just read the interesting parts. The first part is the terms of employments and in the second part I will explain the decision-making process.&lt;/p&gt;

&lt;p&gt;Always be aware of the gray areas in the contract, since there are places where it is hard to decide what to do while something happens. Always try to ask for more information and clarification on those clauses, since this clarification would later help you be assured that you can do your job with no interruptions.&lt;/p&gt;

&lt;p&gt;Throughout the article I try to give examples of a software developer contract, but the general terms apply to all employment contracts.&lt;/p&gt;

&lt;h3 id=&quot;-terms-of-employment&quot;&gt;🗹 &lt;strong&gt;&lt;em&gt;Terms of Employment&lt;/em&gt;&lt;/strong&gt;&lt;/h3&gt;

&lt;h4 id=&quot;1-employee-responsibilities-or-the-assignment&quot;&gt;1. Employee Responsibilities or The Assignment&lt;/h4&gt;

&lt;p&gt;Usually this part includes information about the job responsibilities and how you should do the job. It is either brief like a sentence or two, or divided into multiple statements that try to clarify or include as much as possible. Sentences starting with “your initial responsibilities, but not limited to, …” are usual statements that, instead of clarification, try to include as much responsibility as possible and also account for future changes to your responsibilities. These types of statement are those you should be fully aware of, since when the description of your job or responsibility changes, you cannot deny it, because you already accepted it. Although this doesn’t limit you to do anything legal to take your rights back.&lt;/p&gt;

&lt;p&gt;An example template of these statements would be like this:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;We strive to give you the opportunity of grow and blah blah, but we reserve the right to change the terms whenever we see fit.
Your initial responsibilities is/will be, but not limited to:&lt;/p&gt;
  &lt;ol&gt;
    &lt;li&gt;To work in the team …&lt;/li&gt;
    &lt;li&gt;To do this and that …&lt;/li&gt;
    &lt;li&gt;To make sure everything is OK …#### 2. Reporting Structure&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;p&gt;Some companies are hierarchical and some are flat, or so they say. In every possible organization, there will be a way to report to a higher authority on the matter. It would be your mentor, manager, leader, CTO, CEO or anyone else who is responsible and in charge for making sure that you are doing good and are happy with your job and task. They are the ones you should trust and try not to hide information from, even if you’ve made a mistake. Telling them that you’ve done something great or made a mistake, is the key to the prosperity of the whole company. Otherwise this debt will amass and would lead to losing the job or even the chance of company being dissolved.&lt;/p&gt;

&lt;p&gt;Sometimes you’ll be assigned mentors to let you familiarize with the company, the projects and the team. These mentors are responsible for all of these and they usually are old members or employees of the company and are more senior.&lt;/p&gt;

&lt;h4 id=&quot;3-description-of-the-work&quot;&gt;3. Description of The Work&lt;/h4&gt;

&lt;p&gt;In this section, you will be brief about the description of your work, which usually is different than your responsibilities, which I have discussed above. Your responsibilities are general sentences that give you an idea of what the general vision for this role is, according to company’s vision of personal and corporate grow. This section is more detailed and is usually about the specifics of your job.&lt;/p&gt;

&lt;p&gt;Usually these topics are discussed:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Start date&lt;/strong&gt;: a strict or flexible start date, where you should, obviously, start your work.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Location of work&lt;/strong&gt;: usually this is the company’s address or if your company has branches overseas or need you to travel, those places are usually mentioned here. Some companies try to make it as general as possible to make room for future branches to be included in your contract.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Hours of work&lt;/strong&gt;: either strict or flexible timing is what you should take into consideration. This is sometimes negotiable to some extent, but not always. Strict work hours are the usual 9–5, and flexibility in timing usually depends on the type of the work.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Type of work&lt;/strong&gt;: office-based, &lt;a href=&quot;https://en.wikipedia.org/wiki/Telecommuting&quot;&gt;remote&lt;/a&gt;, work from home (WFH) are some possible combinations of types of works you can do to fulfill your responsibility. Office-based is the most obvious one, which you should “go to work” every single morning and usually come back in the evening. Remote and WFH jobs are those you either work from overseas or work from home. Usually a mix of these is also possible, in which, you come to work on certain days and you have the option to work from home on the others.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Relocation support&lt;/strong&gt;: If you live far from the company you’ve applied for, they may try to help you move to the nearest location to the company’s office. Either the company’s human resources (HR) team handles the relocation or they seek the help of another &lt;a href=&quot;https://en.wikipedia.org/wiki/Relocation_service&quot;&gt;relocation services&lt;/a&gt; company dedicated to help you with relocation, either with or without your family.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Visa sponsorship&lt;/strong&gt;: people in certain countries need visas to to be able to travel and work in a foreign country. Some companies offer this and would help you along the process.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Work permit&lt;/strong&gt;: along with the sponsorship of the visa, a &lt;a href=&quot;https://en.wikipedia.org/wiki/Work_permit&quot;&gt;work permit&lt;/a&gt; is usually needed to be accompanied by the visa, in order for the employee to be able to work legally for the company in a foreign country.
    &lt;h4 id=&quot;4-background-check&quot;&gt;4. Background Check&lt;/h4&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Depending on the country and company, there would be a background check on your profile. This is what happens when you are going to work for high-profile companies or companies that are working in the security industry. This is not something secretive and the company must seek your permission to do this. Along with your offer of employment, you will be presented with another form to sign to give consent about it. The form should include everything they try to do to do background check, like the name of the security consultation company, what they look for and how they’ll perform this action. This is not something to worry about, unless you have something to hide. Be aware and prepared,since almost all your claims will be verified. These are usually checked: where you worked, who you worked with, your qualifications and certifications and all other related pieces of information.&lt;/p&gt;

&lt;h4 id=&quot;5-internship-and-induction&quot;&gt;5. Internship and Induction&lt;/h4&gt;

&lt;p&gt;Some companies have internship periods where you will be employed full- or part-time by the company afterwards. This is something that fresh-graduates are usually familiar with, since it is usually the case that they don’t have enough work experience, and they want to gain this experience, so they seek internship at big or small companies, either paid or otherwise.&lt;/p&gt;

&lt;p&gt;For more experienced personnel, there will be an induction period, of three to six months, where they will be assessed by their contribution to the project(s), team and company or any other Key-Performance Indicators (KPIs). This is usually not the case for all and sometimes is the formality of the job or contract to include this statement. Usually the notice period for the induction period is much shorter, which I’ll talk about it in further topics.&lt;/p&gt;

&lt;h4 id=&quot;6-prohibition&quot;&gt;6. Prohibition&lt;/h4&gt;

&lt;p&gt;Sometimes the company wants to legally prevent you from doing two or more businesses at the same time. This means that you cannot be employed full-time by two companies at the same time. Although they cannot stop you from doing this, but this has its own consequences. Some companies prevent you from doing any other type of business while you are employed by the company or even afterwards, which I’ll talk about it later. Although this seems unfair in some circumstances, it is there to ensure that you are fully focused on the company’s assignment(s).&lt;/p&gt;

&lt;p&gt;You, as an employee, should be fully aware of this. Sometimes it is negotiable. For example, the company may accept the you study and work at the same time or you are working on an open-source project at the same time that usually does not take a lot of your time. So, be prepared to tell them what you do, besides your normal company hours. Since a mutual understanding and trust would later help your achieve great results.&lt;/p&gt;

&lt;h4 id=&quot;7-confidentiality&quot;&gt;7. Confidentiality&lt;/h4&gt;

&lt;p&gt;Company’s trade secrets are very important to the prosperity and growth of the company. So you should always be aware and careful not to share any trade secrets with anyone, especially on social media, where the outreach would be devastating to the company’s plans and future. Also, not everything is confidential, unless clearly stated in the contract, otherwise just ask your manager or mentor about it.&lt;/p&gt;

&lt;p&gt;Statements would be like this:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;All information obtained in the course of work with COMPANY-X shall be deemed to be strictly confidential.&lt;br /&gt;
No such information shall be divulged to any third party, or use for any purpose other than on the performance of your duties.#### 8. Non-Disclosure Agreement, a.k.a. NDA&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Almost always, a &lt;a href=&quot;https://en.wikipedia.org/wiki/Non-disclosure_agreement&quot;&gt;NDA&lt;/a&gt; follows the main contract, which is a type of amendment or appendix to the main contract. NDA is a legal contract between parties in the contract that outlines the confidentiality of information, knowledge or material that is shared between the parties by the means of the contract. It goes on by defining different terms that apply to the sharing of these confidential trade secrets. As noted above, confidential information which are obtained from the company by any means by either parties, belong to the same company, unless the company explicitly confirms that it can be shared with third-parties. For example, you cannot share details of your tech-stack with the world, unless the company confirms it &lt;em&gt;in writing&lt;/em&gt; that you can.&lt;/p&gt;

&lt;h4 id=&quot;9-non-competition-clause&quot;&gt;9. Non-Competition Clause&lt;/h4&gt;

&lt;p&gt;Sometimes companies can’t stand competition. So, they try to drag you into signing amendments or appendices called non-competition agreement. Sometimes it is written in main contract as &lt;a href=&quot;https://en.wikipedia.org/wiki/Non-compete_clause&quot;&gt;the non-competition clause&lt;/a&gt;. This is to ensure that the other party, employee in this case, does not try to engage in any other similar business or trade that competes or is in direct contrast with the current one. Some see this as restrictive, others not. But as long as you try not to do the same exact thing with a competing business, you are good to go, although no one can stop you. I do recommend you to ask for clarification on any of the terms that you seem to be restrictive and limiting.&lt;/p&gt;

&lt;h4 id=&quot;10-ownership-agreements&quot;&gt;10. Ownership Agreements&lt;/h4&gt;

&lt;p&gt;When you start working for an employer, you should realize that you cannot use anything, including intellectual property, source code, documentation or otherwise, which has been created or produced at workplace for any other purpose than the job itself. That holds true, unless you have &lt;em&gt;written permission&lt;/em&gt; from the company, that you can use it somewhere else, or make it open-source. This means that the company owns every single thing that is created on work-hours or even off. Sometimes it is hard to discern which is which, since you may create a similar piece of product on your spare time based on the ideas that are those of the company as a whole.&lt;/p&gt;

&lt;p&gt;As a general piece of advice, do not try to use the company’s assets and properties for other means than the company’s interests, unless you know what you are doing or you have explicit written permission.&lt;/p&gt;

&lt;h4 id=&quot;11-employee-benefits-and-perks&quot;&gt;11. Employee Benefits and Perks&lt;/h4&gt;

&lt;p&gt;Usually each job at each company has its own set of benefits. The &lt;a href=&quot;https://en.wikipedia.org/wiki/Employee_benefits&quot;&gt;benefits&lt;/a&gt; range from housing, transportation, profit sharing and health and retirement benefits to entertainment in or outside the company. Each company has its own set of rules for this. The general rule is that at least some of them are provided by each company. These &lt;em&gt;big and small&lt;/em&gt; incentives for the employees are “rewards” on top of the salary to improve employee retention in the company. Just keep in mind that some of these benefits are taxable in some countries.&lt;/p&gt;

&lt;h4 id=&quot;12-leave&quot;&gt;12. Leave&lt;/h4&gt;

&lt;p&gt;During your employment, you are entitled by law to leave your job, while maintaining your status in the company. Each country and each company has their own set of laws and regulations. Generally you can have vacations, &lt;a href=&quot;https://en.wikipedia.org/wiki/Paid_time_off&quot;&gt;paid time off&lt;/a&gt; (PTO), holidays and other types of leaves, which you are usually paid. This is also negotiable to some extent.&lt;/p&gt;

&lt;p&gt;There is another type of leave, called &lt;a href=&quot;https://en.wikipedia.org/wiki/Leave_of_absence&quot;&gt;leave of absence&lt;/a&gt;, which is either requested by the employer or by the employee based on various grounds. They are also either paid or unpaid. The difference with the above mentioned leaves is that it is used for special circumstances, like active duty from reserve military personnel. This is not usually mentioned in the contract and is left for the law to decide.&lt;/p&gt;

&lt;h4 id=&quot;13-remote-work&quot;&gt;13. Remote Work&lt;/h4&gt;

&lt;p&gt;As is described above, remote work has its own set of rules and practices. In this section of the contract, rules regarding remote work is outlined. As with every other types of work, it has its own set of potentials and drawbacks. Besides that, all the terms should be laid out clearly enough in order not to confuse either parties.&lt;/p&gt;

&lt;p&gt;Generally, &lt;a href=&quot;https://en.wikipedia.org/wiki/Telecommuting&quot;&gt;remote work&lt;/a&gt; is described as a type of work arrangement, in which the employee need not travel or commute to the workplace to do the job. There are two types of remote work. Remote work on specific days of the week (or month), in which the employee is permitted to work from home on certain days handle tasks and get the job done. On other days, they should be at the workplace to have meetings and synchronize with the team. The other type is the true remote work, in which the cost of travel, usually overseas, is unjustifiable or unreasonable for both parties. So the employer uses various types of remote communication tools to facilitate the job.&lt;/p&gt;

&lt;p&gt;This topic probably needs its own article to be fully addressed, but as a whole, contracts for true remote work is different in many terms with normal contracts, since the employer usually need not provide extra benefits to the employee.&lt;/p&gt;

&lt;h4 id=&quot;14-tax&quot;&gt;14. Tax&lt;/h4&gt;

&lt;p&gt;One of the most important and complicated topics of all contracts is tax. There are various taxes to be aware of. The most important one is the income tax, in which you pay some amount of your salary to your country’s tax office (the government). Usually the employer handles all tax deductions and payments, unless your country’s laws are different. The other type is social security contributions or payroll tax, with each country having its own set of laws and regulations, sometimes paid all by the employer and sometimes shared between the two.&lt;/p&gt;

&lt;p&gt;You always should be aware of all the tax regulations of your country which are directly or indirectly related to you and try to seek consultation of a professional on this. Otherwise you’ll get into serious trouble on your tax clearance at the end of fiscal year.&lt;/p&gt;

&lt;h4 id=&quot;15-insurance&quot;&gt;15. Insurance&lt;/h4&gt;

&lt;p&gt;Insurances is very varied, but are usually in two categories: mandatory and voluntary. Mandatory insurances are those imposed on employers either by law or by unions’ agreements to help the employees in need. Since we are not always healthy and there are mishaps and illnesses. This mandatory type of insurance helps the employees and their family to benefit from public healthcare services. Some of them are for welfare of the society and some others are for pension, i.e. when you get old and retire. Usually all of these mandatory insurances are basic types of insurance. In order to increase the coverage of healthcare services to include private healthcare services and have bigger retirement payments and the like, you should have some form of private insurance. Some companies help with group private insurance(s), but I do recommend you to find your own health and life insurance, alongside that.&lt;/p&gt;

&lt;h4 id=&quot;16-salary-review-and-bonuses&quot;&gt;16. Salary Review and Bonuses&lt;/h4&gt;

&lt;p&gt;It usually happens that you are not happy with your job because you are not compensated well. So, this clause ensures that you have the right to negotiate higher amounts while working for the company. Some include it by default and some don’t. So it is up to you to request this to be included in your contract.&lt;/p&gt;

&lt;p&gt;Over time and as the company makes profit, there will be bonuses divided between employees. Usually it is up to the company to decide if they want to pay it or not. If they decide to include such a clause in your contract, they try their best not to put any type of pressure on themselves to pay you any type of bonus and they make it look usually like a unilateral promise with no obligations.&lt;/p&gt;

&lt;h4 id=&quot;17-conflict-of-interest-and-dispute-resolution&quot;&gt;17. Conflict of Interest and Dispute Resolution&lt;/h4&gt;

&lt;p&gt;Life is not all about fairies. &lt;a href=&quot;https://en.wikipedia.org/wiki/Conflict_of_interest&quot;&gt;Conflict of interest&lt;/a&gt; arises when the interest of oneself opposes the interest of others and vice versa. I recommend you to try not to go into those directions, when it is not necessary. If you do, then there are various ways to mitigate such conflicts, but the rule of thumb is not to give away your right to seek help of a professional and eventually seek practice of law, in case the tensions are heightened. There are various ways to &lt;a href=&quot;https://en.wikipedia.org/wiki/Dispute_resolution&quot;&gt;resolve disputes&lt;/a&gt; and deal with conflict of interest, which is out of scope of this article.&lt;/p&gt;

&lt;h4 id=&quot;18-resignation-and-notice-period&quot;&gt;18. Resignation and Notice Period&lt;/h4&gt;

&lt;p&gt;Sometimes you no longer want to work for the company, either you’ve found a new job or want to conquer new frontiers. In this case, you usually resign. You should give a &lt;a href=&quot;https://en.wikipedia.org/wiki/Letter_of_resignation&quot;&gt;letter of resignation&lt;/a&gt; to your employer, thank them about the opportunity they provided you and eventually address the matter of resignation. While resigning, you can not vanish into thin air afterwards. You should respect (the rules of) the contract in this case, too. Notice period is the amount of time you should give to your employer to be aware of your leave and to try to help you with off-boarding and other paperwork. Usually the duration of the notice period before and after induction period is different.&lt;/p&gt;

&lt;h4 id=&quot;19-termination&quot;&gt;19. Termination&lt;/h4&gt;

&lt;p&gt;Sometimes it doesn’t work well between you and the employer and they want to &lt;a href=&quot;https://en.wikipedia.org/wiki/Termination_of_employment&quot;&gt;terminate the contract&lt;/a&gt;. In this case you are either dismissed or laid off, which depends on the decision of the employer. Other times, the duration of contract is ended and they don’t want to extend it. The employer usually communicate in some way with the employees to let them know that the contract is over and they should leave. Although sometimes it becomes tough, especially when you have other responsibilities and family to take care of, but life is life and it waits for no one. So, keep up your high spirit and try to find your next exciting job and move on.&lt;/p&gt;

&lt;h4 id=&quot;20-amendments&quot;&gt;20. Amendments&lt;/h4&gt;

&lt;p&gt;Amendments or appendices are usually internal rules, NDA and other legal documents attached to the main contract. These amendments usually follow the contract and you should sign them, too. Almost always, each amendment has at least one reference in the main contract. So, when reviewing the contract, request accompanying documents, a.k.a. amendments, and review them, too. There are many details in the main contract and the amendments, so try to put enough time to review them and then decide what to do. Seeking the help of a professional is highly recommended, in case you don’t understand some parts of it. Googling about it is also good and would enlighten you even more.&lt;/p&gt;

&lt;h3 id=&quot;-the-decision&quot;&gt;🗹 &lt;strong&gt;&lt;em&gt;The Decision&lt;/em&gt;&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;Three situation would occur after carefully reviewing the contract and its amendments:&lt;/p&gt;

&lt;h4 id=&quot;1-negotiate&quot;&gt;1. Negotiate&lt;/h4&gt;

&lt;p&gt;You are not happy or are confused with one or more parts of the contract and you want to change it, like salary, benefits or other terms and conditions. Go forward and tell them that you want to negotiate and seek clarification on them. Don’t hesitate to negotiate, since losing an offer is better than having a bad contract.&lt;/p&gt;

&lt;h4 id=&quot;2-sign&quot;&gt;2. Sign&lt;/h4&gt;

&lt;p&gt;If you’ve finally decided to sign, now is the best time to do it. Go thank them that they offered you this, and sign it. May you leave happily ever after.&lt;/p&gt;

&lt;h4 id=&quot;3-reject&quot;&gt;3. Reject&lt;/h4&gt;

&lt;p&gt;You have chosen not to accept the offer or you may have been offered a more luxurious contract from another company. Go thank them that they offered you this, and kindly reject it. May you leave happily ever after.&lt;/p&gt;

&lt;p&gt;Last but not least, I do highly appreciate your feedback on this article and would like to hear about it. Hope you enjoyed reading the article as much as I enjoyed writing it.&lt;/p&gt;

&lt;p&gt;Cover image credits: &lt;a href=&quot;http://www.freepik.com&quot;&gt;freepik.com&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">Disclaimer:</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://mostafa.dev/img/1*qA9WpN7JtTveqfwHEYGbWA.jpeg" /><media:content medium="image" url="https://mostafa.dev/img/1*qA9WpN7JtTveqfwHEYGbWA.jpeg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Beginner’s Guide to Load Testing with k6</title><link href="https://mostafa.dev/blog/beginner-s-guide-to-load-testing-with-k6-part-3" rel="alternate" type="text/html" title="Beginner’s Guide to Load Testing with k6" /><published>2019-07-09T00:00:00+02:00</published><updated>2019-07-09T00:00:00+02:00</updated><id>https://mostafa.dev/blog/beginner-s-guide-to-load-testing-with-k6-part-3</id><content type="html" xml:base="https://mostafa.dev/blog/beginner-s-guide-to-load-testing-with-k6-part-3">&lt;p&gt;Now that you know &lt;a href=&quot;https://medium.com/swlh/beginners-guide-to-load-testing-with-k6-85ec614d2f0d&quot;&gt;the basics&lt;/a&gt; and have defined your &lt;a href=&quot;https://medium.com/swlh/beginners-guide-to-load-testing-with-k6-73d55ee23723&quot;&gt;performance goals&lt;/a&gt;, it is now time to write your load-test script and run it using k6. Since k6 scripts can be written in JavaScript, you can easily write them if you have a minimum knowledge of this programming language.&lt;/p&gt;

&lt;h4 id=&quot;k6-test-life-cycle&quot;&gt;k6 Test Life-cycle&lt;/h4&gt;

&lt;p&gt;There are three parts in each test script (actually there is more), which is depicted in the below screenshot:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/1*KHnZgPqBbs0HYg_PWeNITA.png&quot; alt=&quot;&quot; /&gt;Different parts of the k6 script1. &lt;strong&gt;&lt;em&gt;Imports&lt;/em&gt;&lt;/strong&gt;: This is obviously where you can import &lt;a href=&quot;https://docs.k6.io/docs/init-context&quot;&gt;k6 Script API&lt;/a&gt;, and other &lt;a href=&quot;https://docs.k6.io/docs/modules&quot;&gt;JavaScript modules&lt;/a&gt; (libraries) that you desire to make use of. These modules can be loaded using various methods: &lt;a href=&quot;https://docs.k6.io/docs/modules#section-npm-modules&quot;&gt;bundled NPM modules&lt;/a&gt; on your local machine (browserified, but browser APIs are not supported) and &lt;a href=&quot;https://docs.k6.io/docs/modules#section-remote-modules&quot;&gt;remote modules&lt;/a&gt; (from a URL, even CDNJS and GitHub). &lt;em&gt;Hint&lt;/em&gt;: Make sure to make the libraries available to the &lt;a href=&quot;https://hub.docker.com/r/loadimpact/k6&quot;&gt;dockerized version of k6&lt;/a&gt; via mounted volumes, otherwise your script does not find the imports.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;Init code&lt;/em&gt;&lt;/strong&gt;: This is the part of the script that is outside the exported “&lt;em&gt;default&lt;/em&gt;” function. It is usually used to provide options to the whole test, how to run the test, how to distribute it on the cloud, etc. Obviously, it is used for initialization of the whole test itself.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;VU code&lt;/em&gt;&lt;/strong&gt;: k6 supports a feature called virtual users. This means that you can use &lt;em&gt;separate&lt;/em&gt; “smart” virtual users to test your system. The code in this section which is inside the exported “&lt;em&gt;default&lt;/em&gt;” function, is ran over and over inside each VU and the aggregated results of all these VUs are processed and reported by k6. This is where you define your test scenario, which is thoroughly explained further in this article.
There are other stages in &lt;a href=&quot;https://docs.k6.io/docs/test-life-cycle&quot;&gt;the life-cycle of a k6 test&lt;/a&gt;, which includes &lt;em&gt;setup&lt;/em&gt; and &lt;em&gt;tear-down&lt;/em&gt;, which, clearly, are separate from the init and VU code.&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;how-to-run-k6&quot;&gt;How to Run k6?&lt;/h4&gt;

&lt;p&gt;There are various methods of running k6. Since the k6 is distributed in &lt;a href=&quot;https://github.com/loadimpact/k6&quot;&gt;source code&lt;/a&gt; and &lt;a href=&quot;https://github.com/loadimpact/k6/releases&quot;&gt;binary&lt;/a&gt;, you can easily grab and install a binary version on your machine and run it. Supported operating systems include GNU/Linux, Microsoft Windows and Apple macOS. There is also a &lt;a href=&quot;https://hub.docker.com/r/loadimpact/k6&quot;&gt;dockerized version&lt;/a&gt; that you can run on your docker setup.&lt;/p&gt;

&lt;p&gt;No matter where you run the k6, it provides you with the same experience. Here’s the help of the k6 command:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/1*VnQokWG3VNbPH_0Xj2YyBA.png&quot; alt=&quot;&quot; /&gt;k6 helpThe format of running k6 is like “k6 [command]”, which you can then pass your desired command and let it run by k6. Basic available commands, as of version 0.25.1, is as follows. Plus you can get help for each command with this combination:&lt;/p&gt;

&lt;p&gt;k6 &lt;command /&gt; –help* &lt;strong&gt;help&lt;/strong&gt;: shows the above help, well, obviously.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;pause&lt;/strong&gt;: pause a running test.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;resume&lt;/strong&gt;: resume a paused test.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;run&lt;/strong&gt;: run a test with various flags, e.g.–*paused *to run a script in paused mode.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;stats&lt;/strong&gt;: shows statistics about the currently running or paused test entailing number of VUs.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;status&lt;/strong&gt;: show the status of current k6 instance, either running, paused, tainted and the number of VUs.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;version&lt;/strong&gt;: guess what?
These are more advanced commands that I will try to cover in the coming articles:&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;archive&lt;/strong&gt;: creates a bundled &lt;em&gt;tar&lt;/em&gt; file of your script along with all the dependencies, which you can later use with “k6 run”.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;login&lt;/strong&gt;: authenticates with &lt;a href=&quot;https://loadimpact.com/insights/&quot;&gt;Load Impact Insights&lt;/a&gt; cloud service and provides an authentication token to be used by k6.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;cloud&lt;/strong&gt;: runs your authenticated test on the k6 cloud service.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;convert&lt;/strong&gt;: browsers can log requests/responses as HAR (HTTP Archive) files, which you can then convert the HAR file using k6. k6 creates a script from the HAR file, which you can edit and run locally or on the cloud.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;inspect&lt;/strong&gt;: basically outputs the consolidated script options for that script or .tar bundle.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;scale&lt;/strong&gt;: scale a paused/running test with a new number of virtual users (VUs). It can do this either for local or for cloud execution.
Each of these commands has a rich set of options/flags to pass in order to control the behavior of k6. I strongly recommend you to have a look at them, since sometimes you find gems inside.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;test-scenario--interpretation-of-results&quot;&gt;Test Scenario &amp;amp; Interpretation of Results&lt;/h4&gt;

&lt;p&gt;Test scenario is an inseparable part of each test. If you want to test your API or website, you have to have a scenario and eventually turn it into a script, and then pass it to k6 to run.&lt;/p&gt;

&lt;p&gt;Let’s have an example:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;A user checks of the API is up, hence checking the heart beat of our API and then tries to send further messages.&lt;/li&gt;
  &lt;li&gt;Then they try to create a token to be able to access other parts of our API or the private areas.&lt;/li&gt;
  &lt;li&gt;Finally they try to access an endpoint of our API.
[heart-beat]-&amp;gt;[generate-token]-&amp;gt;[get-list-of-users]You also want to add some more criteria and thresholds, to be able to discern more meaningful results from the k6. Although some information, like threshold is new in this article, I’ll try to explain them completely in the upcoming article. You want this scenario to be tested by 100 individual users, starting with 10 users, ramping up to 100 and the gradually down to 0, and to keep the response time of all request below 500ms.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The script would be something like this:&lt;/p&gt;

&lt;p&gt;Example of k6 scenario scriptI have used &lt;a href=&quot;https://httpbin.org&quot;&gt;httpbin.org&lt;/a&gt; as a kitchen-sink for testing k6 with this script. The results of running test for five minutes is as follows:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/1*yY9iJKP_KEcuweo78xfXfA.png&quot; alt=&quot;&quot; /&gt;Output of k6 scenario scriptThe output start with the logo of the k6 being printed to the screen. After that comes the method of execution, being “local” in my case. The output is redirected to the terminal and the name of the script is “test.js”.&lt;/p&gt;

&lt;p&gt;Duration and iterations are empty, since they are automatically calculated from the stages. The number of (max) VUs are 100 and the progress bar shows that it is done in five minutes.&lt;/p&gt;

&lt;p&gt;“v1 API Testing” and other group names are followed by a white full block sign “█” and the checks are all ticked and green, indicating they are passed in all cases.&lt;/p&gt;

&lt;p&gt;All the checks in the tests are passed, specifically 56213 checks in 33741 requests. The amount of data sent and received, vus, iterations and some other metrics are also shown.&lt;/p&gt;

&lt;p&gt;The very important part is the metrics that start with &lt;em&gt;http&lt;/em&gt;. They signify the average, minimum, maximum, p(90) and p(95) of the amount of time each request or group of request has taken to complete.&lt;/p&gt;

&lt;p&gt;Since we have defined the average threshold to be 500ms. Since the average time of all requests hasn’t taken that long, the test is passed.&lt;/p&gt;

&lt;p&gt;The results shown on screen is the aggregated results on all the tests. If you want to be able to use all the generated data, and not only the aggregated ones, you should use the -o flag to send the output to either a files, a software or the cloud service.&lt;/p&gt;

&lt;p&gt;The raw results can be written to a JSON file using &lt;a href=&quot;https://docs.k6.io/docs/results-output#section-json-output&quot;&gt;JSON plugin&lt;/a&gt;. There are other plugins that push the metrics to &lt;a href=&quot;https://docs.k6.io/docs/results-output#section-influxdb-output&quot;&gt;InfluxDB&lt;/a&gt;, &lt;a href=&quot;https://docs.k6.io/docs/results-output#section-apache-kafka-output&quot;&gt;Apache Kafka&lt;/a&gt;, &lt;a href=&quot;https://docs.k6.io/docs/results-output#section-statsd-output&quot;&gt;StatsD&lt;/a&gt; or &lt;a href=&quot;https://docs.k6.io/docs/results-output#section-datadog-output&quot;&gt;Datadog&lt;/a&gt;. The last (and probably the best) option would be to use the &lt;a href=&quot;https://docs.k6.io/docs/results-output#section-load-impact-insights-output&quot;&gt;Load Impact plugin&lt;/a&gt; that streams your test results to the Load Impact cloud platform.&lt;/p&gt;

&lt;p&gt;In this article I tried my best to show you how to write a pretty simple test scenario script and how to run to the load test using k6.&lt;/p&gt;

&lt;p&gt;In the next article I’ll try to turn concepts I’ve talked about on &lt;a href=&quot;https://medium.com/swlh/beginners-guide-to-load-testing-with-k6-73d55ee23723&quot;&gt;the second article&lt;/a&gt; — Performance Goals and k6 Metrics — into features supported by k6 that you can use to have a successful load or acceptance testing.&lt;/p&gt;

&lt;p&gt;As always, I do welcome your feedback. Please don’t hesitate to write your comments, questions and feedback below.&lt;/p&gt;</content><author><name></name></author><summary type="html">Now that you know the basics and have defined your performance goals, it is now time to write your load-test script and run it using k6. Since k6 scripts can be written in JavaScript, you can easily write them if you have a minimum knowledge of this programming language.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://mostafa.dev/img/1*yY9iJKP_KEcuweo78xfXfA.png" /><media:content medium="image" url="https://mostafa.dev/img/1*yY9iJKP_KEcuweo78xfXfA.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Beginner’s Guide to Load Testing with k6</title><link href="https://mostafa.dev/blog/beginner-s-guide-to-load-testing-with-k6-part-2" rel="alternate" type="text/html" title="Beginner’s Guide to Load Testing with k6" /><published>2019-06-19T00:00:00+02:00</published><updated>2019-06-19T00:00:00+02:00</updated><id>https://mostafa.dev/blog/beginner-s-guide-to-load-testing-with-k6-part-2</id><content type="html" xml:base="https://mostafa.dev/blog/beginner-s-guide-to-load-testing-with-k6-part-2">&lt;p&gt;Performance testing is an umbrella term for a group of tests that encompasses many types of tests, as discussed in &lt;a href=&quot;https://medium.com/swlh/beginners-guide-to-load-testing-with-k6-85ec614d2f0d&quot;&gt;the first part of this series&lt;/a&gt;. Each test type tries to answer a set of questions to make the performance testing process more goal-oriented. This means that just running tests is not enough, you have to have a set of goals to reach.&lt;/p&gt;

&lt;p&gt;Since we’re testing an API or a website, the following goals may be relevant, in which you can choose either one or more:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Concurrency&lt;/strong&gt;: systems which would set this goal, usually have a concept of end-user and need to see how the system behaves while many concurrent users try to access the system. They basically want to test how many of requests fail/pass under high loads of users. This both includes many concurrent users and each requesting multiple resources at the same time.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Throughput&lt;/strong&gt;: systems with no concept of end-users, would set this goal to see how the system behaves overall, while there is a ton of requests/responses coming in/out of the system.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Server response time&lt;/strong&gt;: this goal signifies the time it takes from the initial request from the client to the server up until a response is sent back from the server.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Regression testing&lt;/strong&gt;: sometimes the goal is not to put “heavy load” on the system, but is more about “normal load” and functional and regression testing to see how a change would affect our system’s performance and if it still adheres to our defined SLAs.
The general idea is to measure how a system or system of systems behave(s) under heavy load, in terms of speed, scalability, stability and resiliency. Each of which can be measured by these goals.&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;em&gt;*Speed&lt;/em&gt; ***can be measured by time it takes for request to be handled by the server and how much time it takes for this request/response to happen.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Scalability&lt;/strong&gt; can be measured by how well the system scales if the load is increased and by measuring if it sustains over a period of time under this load.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Stability&lt;/strong&gt; can be measured by how well the system sustains the load and to see if it stands against a high number of errors and events and still stays responsive and stable.&lt;/li&gt;
  &lt;li&gt;**Resiliency **can be measured by how the system recovers from crashes and down-times and responds to requests, after putting too much or too frequent load on it and eventually crashing the system.
    &lt;h4 id=&quot;rerunning-tests-to-verify-the-results&quot;&gt;Rerunning Tests to Verify the Results&lt;/h4&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;You can rerun the tests to see if they hold almost the same results during different tests and compare the tests to see if they deviate.&lt;/p&gt;

&lt;p&gt;If they are almost the same, you can analyze the tests and derive your results, otherwise you should pinpoint where it deviates and try to find a way to prevent it from happening, like a bottleneck.&lt;/p&gt;

&lt;h4 id=&quot;k6-and-the-metrics&quot;&gt;&lt;strong&gt;k6 and the Metrics&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;k6 supports a set of built-in and custom metrics that can be used to measure various things and to either achieve the above mentioned goals or prove them wrong. The metrics that can be used to define custom metrics are: &lt;a href=&quot;https://docs.k6.io/docs/counter-k6metrics&quot;&gt;Counter&lt;/a&gt;, &lt;a href=&quot;https://docs.k6.io/docs/gauge-k6metrics&quot;&gt;Gauge&lt;/a&gt;, &lt;a href=&quot;https://docs.k6.io/docs/rate-k6metrics&quot;&gt;Rate&lt;/a&gt; and &lt;a href=&quot;https://docs.k6.io/docs/trend-k6metrics&quot;&gt;Trend&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/1*4vdPNtvMGfnuls5_7rG8mQ.png&quot; alt=&quot;&quot; /&gt;k6 built-in metricsAs you’ve probably seen above, these following tables describes reported built-in metrics, present on all tests:&lt;/p&gt;

&lt;p&gt;k6 built-in metrics, &lt;strong&gt;Credits&lt;/strong&gt;: &lt;a href=&quot;https://docs.k6.io/docs/result-metrics#section-built-in-metrics&quot;&gt;https://docs.k6.io/docs/result-metrics#section-built-in-metrics&lt;/a&gt;k6 HTTP-specific built-in metrics, &lt;strong&gt;Credits&lt;/strong&gt;: &lt;a href=&quot;https://docs.k6.io/docs/result-metrics#section-http-specific-built-in-metrics&quot;&gt;https://docs.k6.io/docs/result-metrics#section-http-specific-built-in-metrics&lt;/a&gt;#### Custom (non-built-in) Metrics&lt;/p&gt;

&lt;h4 id=&quot;1-counter&quot;&gt;1. Counter&lt;/h4&gt;

&lt;p&gt;This is a simple cumulative counter that can be used to measure any cumulative value like number of errors during the test.&lt;/p&gt;

&lt;p&gt;k6 Counter metricAs you can see in the above example, it counts the number of 404 errors that are returned by the test. The result is evident in the screenshot below:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/1*caIiiiUAjcSD49mVuBGJfA.png&quot; alt=&quot;&quot; /&gt;Results of k6 Counter metricSince it is a beginner’s guide, I try to stick with simple examples, but you can extend and customize them to your specific case.&lt;/p&gt;

&lt;h4 id=&quot;2-gauge&quot;&gt;2. Gauge&lt;/h4&gt;

&lt;p&gt;This metric lets you keep the last thing that is added to it. It’s a simple over-writable metric that holds its last added value.&lt;/p&gt;

&lt;p&gt;This metric can be used to retain the last value of any test item, be it response time, delay or any other user-defined value.&lt;/p&gt;

&lt;p&gt;If you run the following code, you’ll see that it catches the latest error code, which is 404.&lt;/p&gt;

&lt;p&gt;k6 Gauge metricThe result of the test is presented in the screenshot below.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/1*i1cKpSpRMgjMy9wg_-eZ1Q.png&quot; alt=&quot;&quot; /&gt;Results of k6 Gauge metric#### 3. Rate&lt;/p&gt;

&lt;p&gt;This built-in metric keeps the rate between non-zero and zero/false values. For example if you add two false and one true value, the percentage becomes 33%.&lt;/p&gt;

&lt;p&gt;It can be used to keep track of the rate of successful request/responses and compare them with errors.&lt;/p&gt;

&lt;p&gt;In the following piece of code, you can see that I added res.error_code as a measure to see how many errors I’ll catch.&lt;/p&gt;

&lt;p&gt;k6 Rate metricBelow is the result of the test, which is 100% errors.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/1*OiuMqAnYlA_Ir-oLZK61xg.png&quot; alt=&quot;&quot; /&gt;Results of k6 Rate metric#### 4. Trend&lt;/p&gt;

&lt;p&gt;This metric allows you to statistically calculate your custom value. It will give you minimum, maximum, average and percentiles, as is evident in the above screenshots for http_req* requests.&lt;/p&gt;

&lt;p&gt;k6 Rate metricThe above example of rate metric shows how to calculate the sending and receiving time without taking into account the waiting time. The result is shown below:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/1*Ls79S9pcf_T5xKEPvh_qrA.png&quot; alt=&quot;&quot; /&gt;Results of k6 Rate metricIn this part, I’ve tried to describe the goals of performance testing and how one can use metrics to achieve those goals. In the next sections, I’ll try to go more in-depth and present you more details on how to define custom metrics and how to use them.&lt;/p&gt;

&lt;p&gt;Now that you have a good grasp of performance goals and k6 metrics, you can move to &lt;a href=&quot;https://medium.com/swlh/beginners-guide-to-load-testing-with-k6-ff155885b6db&quot;&gt;the next article&lt;/a&gt;, in which I try to show you how to write and run a k6 script.&lt;/p&gt;</content><author><name></name></author><summary type="html">Performance testing is an umbrella term for a group of tests that encompasses many types of tests, as discussed in the first part of this series. Each test type tries to answer a set of questions to make the performance testing process more goal-oriented. This means that just running tests is not enough, you have to have a set of goals to reach.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://mostafa.dev/img/1*PGbRNYX0UqKvho2X0ROzAg.png" /><media:content medium="image" url="https://mostafa.dev/img/1*PGbRNYX0UqKvho2X0ROzAg.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>